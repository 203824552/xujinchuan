机器学习根据函数的输入输出，可以分为回归或者分类
生成式学习是输出有结构的物件
使用损失值loss进行函数好坏的评判
损失值可以根据不同训练集之间进行参考
模型训练需要提前设计好超参数
可以选择逐个生成或者一次性生成的生成策略
一次到位速度快但准确性相形见绌，常用于影像
也有n次到位等改进方法

神经网络的结构对训练结果有较大的影响，
但难以判断多少层多少神经元最为合适
 训练过程是通过梯度进行反向传播


cnn一般首先将图片按照三种颜色展开为一维向量
不使用全链接而是使用部分视野进行输入，即，卷积核
图片通过卷积层形成特征图（通过filter计算）
多个卷积层导致视野会越来越大
pooling的作用为把特征图变小


自注意力机制，就可以观察前后，考虑了全局
并且自注意力可以平行运行，速度更快比之rnn
因为rnn只能从左往右生成，根据生成的加入继续新的生成
