{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:47:17.574092Z",
     "iopub.status.busy": "2023-01-28T05:47:17.573588Z",
     "iopub.status.idle": "2023-01-28T05:47:26.438523Z",
     "shell.execute_reply": "2023-01-28T05:47:26.437645Z",
     "shell.execute_reply.started": "2023-01-28T05:47:17.574069Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.4.2)\r\n",
      "Collecting paddlenlp\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a5/de/3f20df026e48eae755ea06cbd587dd845767ac2d04e3bcf5e24cdb62cc4f/paddlenlp-2.5.0-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting fastapi\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/89/adf4525d1870021b65ec562e83e9f46d96494ad95f238d0264ef1ab6b604/fastapi-0.89.1-py3-none-any.whl (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.96)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.1)\r\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (3.20.0)\r\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.4.0)\r\n",
      "Collecting uvicorn\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/f3/f39ac8ac3bdf356b4934b8f7e56173e96681f67ef0cd92bd33a5059fae9e/uvicorn-0.20.0-py3-none-any.whl (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.7.0)\r\n",
      "Collecting typer\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0d/44/56c3f48d2bb83d76f5c970aef8e2c3ebd6a832f09e3621c5395371fe6999/typer-0.7.0-py3-none-any.whl (38 kB)\r\n",
      "Requirement already satisfied: rich in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (12.6.0)\r\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: paddle2onnx in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Collecting huggingface-hub>=0.11.1\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/41/76/50cd8ffb78fa5ef9b11e972ee92514aafd99790e838a1eafbde6a28b3962/huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.3.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (2022.11.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (10.0.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (1.1.5)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (4.2.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (5.1.2)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.3)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (3.1.0)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets>=2.0.0->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (3.0.12)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub>=0.11.1->paddlenlp) (4.3.0)\r\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/6a/a3b9a51b886eeee570ddb32ae64a8d2fd00cd25cb1daaf82260188d2d1e4/pydantic-1.10.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hCollecting starlette==0.22.0\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/4e/30eda84159d5b3ad7fe663c40c49b16dd17436abe838f10a56c34bee44e8/starlette-0.22.0-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from starlette==0.22.0->fastapi->paddlenlp) (3.6.1)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (0.9.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rich->paddlenlp) (2.13.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from typer->paddlenlp) (8.0.4)\r\n",
      "Collecting h11>=0.8\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.1.1)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (8.2.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (2.2.3)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (0.8.53)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (0.16.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (3.0.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2.8.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp) (2019.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (22.1.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (2.1.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (6.0.2)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (0.13.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.9)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (1.25.11)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=2.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (0.18.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp) (3.9.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets>=2.0.0->paddlenlp) (3.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (1.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp) (2.8.2)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi->paddlenlp) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp) (56.2.0)\r\n",
      "Installing collected packages: pydantic, h11, starlette, huggingface-hub, uvicorn, typer, fastapi, paddlenlp\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.11.0\r\n",
      "    Uninstalling huggingface-hub-0.11.0:\r\n",
      "      Successfully uninstalled huggingface-hub-0.11.0\r\n",
      "  Attempting uninstall: paddlenlp\r\n",
      "    Found existing installation: paddlenlp 2.4.2\r\n",
      "    Uninstalling paddlenlp-2.4.2:\r\n",
      "      Successfully uninstalled paddlenlp-2.4.2\r\n",
      "Successfully installed fastapi-0.89.1 h11-0.14.0 huggingface-hub-0.12.0 paddlenlp-2.5.0 pydantic-1.10.4 starlette-0.22.0 typer-0.7.0 uvicorn-0.20.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting wordcloud==1.8.2.2\r\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/05/1e/ff1052b62f233243f3d088d0815bf5ca0ed31f1aa64ae060dd78f3e1d636/wordcloud-1.8.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.2/435.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from wordcloud==1.8.2.2) (8.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from wordcloud==1.8.2.2) (1.19.5)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from wordcloud==1.8.2.2) (2.2.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (3.0.9)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (2019.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (0.10.0)\r\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->wordcloud==1.8.2.2) (1.16.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud==1.8.2.2) (56.2.0)\r\n",
      "Installing collected packages: wordcloud\r\n",
      "Successfully installed wordcloud-1.8.2.2\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U paddlenlp\n",
    "!pip install wordcloud==1.8.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:47:26.440815Z",
     "iopub.status.busy": "2023-01-28T05:47:26.440089Z",
     "iopub.status.idle": "2023-01-28T05:47:52.920908Z",
     "shell.execute_reply": "2023-01-28T05:47:52.920111Z",
     "shell.execute_reply.started": "2023-01-28T05:47:26.440785Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:47:29,468] [    INFO] - Downloading model_state.pdparams from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/model_state.pdparams\r\n",
      "100%|██████████| 450M/450M [00:06<00:00, 76.6MB/s] \r\n",
      "[2023-01-28 13:47:36,713] [    INFO] - Downloading model_config.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/model_config.json\r\n",
      "100%|██████████| 474/474 [00:00<00:00, 476kB/s]\r\n",
      "[2023-01-28 13:47:36,760] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/vocab.txt\r\n",
      "100%|██████████| 182k/182k [00:00<00:00, 24.0MB/s]\r\n",
      "[2023-01-28 13:47:36,902] [    INFO] - Downloading special_tokens_map.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/special_tokens_map.json\r\n",
      "100%|██████████| 112/112 [00:00<00:00, 165kB/s]\r\n",
      "[2023-01-28 13:47:36,940] [    INFO] - Downloading tokenizer_config.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/tokenizer_config.json\r\n",
      "100%|██████████| 235/235 [00:00<00:00, 226kB/s]\r\n",
      "[2023-01-28 13:47:37,005] [    INFO] - loading configuration file /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base/model_config.json\r\n",
      "[2023-01-28 13:47:37,008] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"UIE\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-28 13:47:37,010] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base/config.json\r\n",
      "W0128 13:47:38.993942   274 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0128 13:47:38.996659   274 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-01-28 13:47:39,848] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n",
      "\r\n",
      "[2023-01-28 13:47:39,851] [    INFO] - All the weights of UIE were initialized from the model checkpoint at /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n",
      "[2023-01-28 13:47:39,854] [    INFO] - Converting to the inference model cost a little time.\r\n",
      "[2023-01-28 13:47:50,014] [    INFO] - The inference model save in the path:/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base/static/inference\r\n",
      "[2023-01-28 13:47:52,034] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'情感倾向[正向，负向]': [{'probability': 0.996646058824652, 'text': '正向'}]}]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from pprint import pprint\n",
    "\n",
    "schema = ['情感倾向[正向，负向]']\n",
    "senta = Taskflow(\"sentiment_analysis\", model=\"uie-senta-base\", schema=schema)\n",
    "pprint(senta('蛋糕味道不错，店家服务也很好'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:47:52.922793Z",
     "iopub.status.busy": "2023-01-28T05:47:52.922146Z",
     "iopub.status.idle": "2023-01-28T05:47:56.128852Z",
     "shell.execute_reply": "2023-01-28T05:47:56.128203Z",
     "shell.execute_reply.started": "2023-01-28T05:47:52.922763Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:47:55,898] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'评价维度': [{'end': 4,\r\n",
      "            'probability': 0.9105472387838915,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9998829392709467,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 6,\r\n",
      "                                   'probability': 0.9946981266891619,\r\n",
      "                                   'start': 4,\r\n",
      "                                   'text': '不错'}]},\r\n",
      "            'start': 2,\r\n",
      "            'text': '味道'},\r\n",
      "           {'end': 11,\r\n",
      "            'probability': 0.970909421275195,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9999327669598301,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 15,\r\n",
      "                                   'probability': 0.9897221019724611,\r\n",
      "                                   'start': 13,\r\n",
      "                                   'text': '热情'}]},\r\n",
      "            'start': 9,\r\n",
      "            'text': '服务'}]}]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from pprint import pprint\n",
    "\n",
    "schema =  [{\"评价维度\":[\"观点词\", \"情感倾向[正向,负向,未提及]\"]}]\n",
    "senta = Taskflow(\"sentiment_analysis\", model=\"uie-senta-base\", schema=schema)\n",
    "pprint(senta('蛋糕味道不错，店家服务也很热情'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:47:56.131285Z",
     "iopub.status.busy": "2023-01-28T05:47:56.130546Z",
     "iopub.status.idle": "2023-01-28T05:47:59.228759Z",
     "shell.execute_reply": "2023-01-28T05:47:59.228116Z",
     "shell.execute_reply.started": "2023-01-28T05:47:56.131260Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:47:59,036] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'评价维度': [{'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9999312170965595,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 8,\r\n",
      "                                   'probability': 0.9998772175681552,\r\n",
      "                                   'start': 7,\r\n",
      "                                   'text': '大'}]},\r\n",
      "            'text': '房间'},\r\n",
      "           {'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9999939203353847,\r\n",
      "                                               'text': '未提及'}]},\r\n",
      "            'text': '位置'},\r\n",
      "           {'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9997340617174757,\r\n",
      "                                               'text': '负向'}],\r\n",
      "                          '观点词': [{'end': 25,\r\n",
      "                                   'probability': 0.998841669863026,\r\n",
      "                                   'start': 24,\r\n",
      "                                   'text': '贵'}]},\r\n",
      "            'text': '价格'}]}]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from pprint import pprint\n",
    "\n",
    "# define schema for pre-defined aspects, schema\n",
    "schema = [\"观点词\", \"情感倾向[正向,负向,未提及]\"]\n",
    "aspects = [\"房间\", \"位置\", \"价格\"]\n",
    "# set aspects for Taskflow\n",
    "senta = Taskflow(\"sentiment_analysis\", model=\"uie-senta-base\", schema=schema, aspects=aspects)\n",
    "pprint(senta(\"这家店的房间很大，店家服务也很热情，就是价格有点贵\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:47:59.230212Z",
     "iopub.status.busy": "2023-01-28T05:47:59.229630Z",
     "iopub.status.idle": "2023-01-28T05:48:06.847181Z",
     "shell.execute_reply": "2023-01-28T05:48:06.846375Z",
     "shell.execute_reply.started": "2023-01-28T05:47:59.230186Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:47:59,232] [    INFO] - Downloading model_state.pdparams from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-mini/model_state.pdparams\r\n",
      "100%|██████████| 103M/103M [00:01<00:00, 75.1MB/s] \r\n",
      "[2023-01-28 13:48:01,032] [    INFO] - Downloading model_config.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-mini/model_config.json\r\n",
      "100%|██████████| 507/507 [00:00<00:00, 608kB/s]\r\n",
      "[2023-01-28 13:48:01,075] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-mini/vocab.txt\r\n",
      "100%|██████████| 182k/182k [00:00<00:00, 26.3MB/s]\r\n",
      "[2023-01-28 13:48:01,181] [    INFO] - Downloading special_tokens_map.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-mini/special_tokens_map.json\r\n",
      "100%|██████████| 112/112 [00:00<00:00, 151kB/s]\r\n",
      "[2023-01-28 13:48:01,238] [    INFO] - Downloading tokenizer_config.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-mini/tokenizer_config.json\r\n",
      "100%|██████████| 235/235 [00:00<00:00, 177kB/s]\r\n",
      "[2023-01-28 13:48:01,305] [    INFO] - loading configuration file /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-mini/model_config.json\r\n",
      "[2023-01-28 13:48:01,308] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"UIE\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 384,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 1536,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 6,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 16,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-28 13:48:01,310] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-mini/config.json\r\n",
      "[2023-01-28 13:48:01,696] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n",
      "\r\n",
      "[2023-01-28 13:48:01,698] [    INFO] - All the weights of UIE were initialized from the model checkpoint at /home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-mini.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n",
      "[2023-01-28 13:48:01,701] [    INFO] - Converting to the inference model cost a little time.\r\n",
      "[2023-01-28 13:48:05,887] [    INFO] - The inference model save in the path:/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-mini/static/inference\r\n",
      "[2023-01-28 13:48:06,696] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-mini'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'评价维度': [{'end': 4,\r\n",
      "            'probability': 0.9029286765478162,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9922665529530477,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 6,\r\n",
      "                                   'probability': 0.9983145467490786,\r\n",
      "                                   'start': 4,\r\n",
      "                                   'text': '不错'}]},\r\n",
      "            'start': 2,\r\n",
      "            'text': '味道'},\r\n",
      "           {'end': 11,\r\n",
      "            'probability': 0.9585826828154538,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9962656648067139,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 15,\r\n",
      "                                   'probability': 0.9828564570389915,\r\n",
      "                                   'start': 13,\r\n",
      "                                   'text': '热情'}]},\r\n",
      "            'start': 9,\r\n",
      "            'text': '服务'}]}]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from pprint import pprint\n",
    "\n",
    "schema =  [{\"评价维度\":[\"观点词\", \"情感倾向[正向,负向,未提及]\"]}]\n",
    "senta = Taskflow(\"sentiment_analysis\", model=\"uie-senta-mini\", schema=schema)\n",
    "pprint(senta(\"蛋糕味道不错，店家服务也很热情\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:48:06.849177Z",
     "iopub.status.busy": "2023-01-28T05:48:06.848493Z",
     "iopub.status.idle": "2023-01-28T05:48:35.102353Z",
     "shell.execute_reply": "2023-01-28T05:48:35.101439Z",
     "shell.execute_reply.started": "2023-01-28T05:48:06.849142Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:48:14,386] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/home/aistudio/.paddlenlp/taskflow/sentiment_analysis/uie-senta-base'.\r\n",
      "The results of sentiment analysis has been saved to: ./outputs/sentiment_analysis.json\r\n",
      "This run take 24.239899396896362 seconds.\r\n"
     ]
    }
   ],
   "source": [
    "!python batch_predict.py \\\n",
    "    --file_path \"./data/data184040/test_hotel.txt\" \\\n",
    "    --save_path \"./outputs/sentiment_analysis.json\" \\\n",
    "    --model \"uie-senta-base\" \\\n",
    "    --schema \"[{'评价维度': ['观点词', '情感倾向[正向,负向,未提及]']}]\" \\\n",
    "    --batch_size 4 \\\n",
    "    --max_seq_len 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:48:35.103975Z",
     "iopub.status.busy": "2023-01-28T05:48:35.103615Z",
     "iopub.status.idle": "2023-01-28T05:48:47.803194Z",
     "shell.execute_reply": "2023-01-28T05:48:47.802351Z",
     "shell.execute_reply.started": "2023-01-28T05:48:35.103951Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images has been saved to: ./outputs/images\r\n"
     ]
    }
   ],
   "source": [
    "!python visual_analysis.py \\\n",
    "    --file_path \"./outputs/sentiment_analysis.json\" \\\n",
    "    --save_dir \"./outputs/images\" \\\n",
    "    --font_path \"./SimHei.ttf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行后图片将保存在save_dir指定的目录中，其中可视化结果展示如下。\n",
    "\n",
    "<center><img src=\"https://ai-studio-static-online.cdn.bcebos.com/0a7dda1fd5294be781eb79f45fd24aafd1a5492f6faf4114978ff97c0dc68f00\" /></center>\n",
    "<center>图4 情感分析可视化结果图</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:48:47.804951Z",
     "iopub.status.busy": "2023-01-28T05:48:47.804423Z",
     "iopub.status.idle": "2023-01-28T05:56:37.390999Z",
     "shell.execute_reply": "2023-01-28T05:56:37.389974Z",
     "shell.execute_reply.started": "2023-01-28T05:48:47.804925Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:48:50,772] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'uie-senta-base'.\r\n",
      "[2023-01-28 13:48:50,772] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh_vocab.txt and saved to /home/aistudio/.paddlenlp/models/uie-senta-base\r\n",
      "[2023-01-28 13:48:50,805] [    INFO] - Downloading ernie_3.0_base_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_base_zh_vocab.txt\r\n",
      "100%|████████████████████████████████████████| 182k/182k [00:00<00:00, 24.8MB/s]\r\n",
      "[2023-01-28 13:48:50,976] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/uie-senta-base/tokenizer_config.json\r\n",
      "[2023-01-28 13:48:50,976] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/uie-senta-base/special_tokens_map.json\r\n",
      "[2023-01-28 13:48:50,978] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-28 13:48:50,979] [    INFO] - Configuration saved in /home/aistudio/.paddlenlp/models/uie-senta-base/config.json\r\n",
      "[2023-01-28 13:48:50,980] [    INFO] - Downloading uie_senta_base.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/uie/uie_senta_base.pdparams\r\n",
      "100%|████████████████████████████████████████| 450M/450M [00:06<00:00, 76.8MB/s]\r\n",
      "W0128 13:48:59.160457   867 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0128 13:48:59.163129   867 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-01-28 13:49:00,012] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n",
      "\r\n",
      "[2023-01-28 13:49:00,012] [    INFO] - All the weights of UIE were initialized from the model checkpoint at uie-senta-base.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n",
      "global step 10, epoch: 1, loss: 0.00166, speed: 1.64 step/s\r\n",
      "global step 20, epoch: 1, loss: 0.00210, speed: 2.11 step/s\r\n",
      "global step 30, epoch: 1, loss: 0.00195, speed: 2.09 step/s\r\n",
      "global step 40, epoch: 1, loss: 0.00183, speed: 2.08 step/s\r\n",
      "global step 50, epoch: 1, loss: 0.00172, speed: 2.09 step/s\r\n",
      "global step 60, epoch: 1, loss: 0.00167, speed: 2.08 step/s\r\n",
      "global step 70, epoch: 1, loss: 0.00162, speed: 2.07 step/s\r\n",
      "global step 80, epoch: 1, loss: 0.00157, speed: 2.08 step/s\r\n",
      "global step 90, epoch: 1, loss: 0.00151, speed: 2.08 step/s\r\n",
      "global step 100, epoch: 1, loss: 0.00147, speed: 2.08 step/s\r\n",
      "[2023-01-28 13:49:49,486] [    INFO] - Configuration saved in ./checkpoint/model_100/config.json\r\n",
      "[2023-01-28 13:49:50,355] [    INFO] - tokenizer config file saved in ./checkpoint/model_100/tokenizer_config.json\r\n",
      "[2023-01-28 13:49:50,355] [    INFO] - Special tokens file saved in ./checkpoint/model_100/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.85it/s]\r\n",
      "Evaluation precision: 0.89633, recall: 0.85041, F1: 0.87277\r\n",
      "best F1 performence has been updated: 0.00000 --> 0.87277\r\n",
      "[2023-01-28 13:49:57,371] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:49:58,231] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:49:58,232] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 110, epoch: 1, loss: 0.00145, speed: 2.08 step/s\r\n",
      "global step 120, epoch: 1, loss: 0.00140, speed: 2.08 step/s\r\n",
      "global step 130, epoch: 1, loss: 0.00139, speed: 2.07 step/s\r\n",
      "global step 140, epoch: 1, loss: 0.00137, speed: 2.07 step/s\r\n",
      "global step 150, epoch: 1, loss: 0.00134, speed: 2.08 step/s\r\n",
      "global step 160, epoch: 1, loss: 0.00131, speed: 2.06 step/s\r\n",
      "global step 170, epoch: 1, loss: 0.00128, speed: 2.07 step/s\r\n",
      "global step 180, epoch: 1, loss: 0.00128, speed: 2.07 step/s\r\n",
      "global step 190, epoch: 1, loss: 0.00126, speed: 2.07 step/s\r\n",
      "global step 200, epoch: 1, loss: 0.00123, speed: 2.07 step/s\r\n",
      "[2023-01-28 13:50:46,498] [    INFO] - Configuration saved in ./checkpoint/model_200/config.json\r\n",
      "[2023-01-28 13:50:47,360] [    INFO] - tokenizer config file saved in ./checkpoint/model_200/tokenizer_config.json\r\n",
      "[2023-01-28 13:50:47,361] [    INFO] - Special tokens file saved in ./checkpoint/model_200/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.85it/s]\r\n",
      "Evaluation precision: 0.89339, recall: 0.85861, F1: 0.87565\r\n",
      "best F1 performence has been updated: 0.87277 --> 0.87565\r\n",
      "[2023-01-28 13:50:54,374] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:50:58,134] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:50:58,135] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 210, epoch: 1, loss: 0.00121, speed: 2.06 step/s\r\n",
      "global step 220, epoch: 1, loss: 0.00120, speed: 2.07 step/s\r\n",
      "global step 230, epoch: 1, loss: 0.00119, speed: 2.07 step/s\r\n",
      "global step 240, epoch: 1, loss: 0.00117, speed: 2.07 step/s\r\n",
      "global step 250, epoch: 1, loss: 0.00117, speed: 2.06 step/s\r\n",
      "global step 260, epoch: 1, loss: 0.00116, speed: 2.13 step/s\r\n",
      "global step 270, epoch: 2, loss: 0.00114, speed: 2.05 step/s\r\n",
      "global step 280, epoch: 2, loss: 0.00113, speed: 2.07 step/s\r\n",
      "global step 290, epoch: 2, loss: 0.00112, speed: 2.07 step/s\r\n",
      "global step 300, epoch: 2, loss: 0.00111, speed: 2.06 step/s\r\n",
      "[2023-01-28 13:51:46,429] [    INFO] - Configuration saved in ./checkpoint/model_300/config.json\r\n",
      "[2023-01-28 13:51:47,301] [    INFO] - tokenizer config file saved in ./checkpoint/model_300/tokenizer_config.json\r\n",
      "[2023-01-28 13:51:47,301] [    INFO] - Special tokens file saved in ./checkpoint/model_300/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.79it/s]\r\n",
      "Evaluation precision: 0.89744, recall: 0.86066, F1: 0.87866\r\n",
      "best F1 performence has been updated: 0.87565 --> 0.87866\r\n",
      "[2023-01-28 13:51:54,407] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:51:58,176] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:51:58,176] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 310, epoch: 2, loss: 0.00109, speed: 2.06 step/s\r\n",
      "global step 320, epoch: 2, loss: 0.00108, speed: 2.06 step/s\r\n",
      "global step 330, epoch: 2, loss: 0.00107, speed: 2.06 step/s\r\n",
      "global step 340, epoch: 2, loss: 0.00106, speed: 2.06 step/s\r\n",
      "global step 350, epoch: 2, loss: 0.00105, speed: 2.06 step/s\r\n",
      "global step 360, epoch: 2, loss: 0.00105, speed: 2.05 step/s\r\n",
      "global step 370, epoch: 2, loss: 0.00104, speed: 2.05 step/s\r\n",
      "global step 380, epoch: 2, loss: 0.00103, speed: 2.05 step/s\r\n",
      "global step 390, epoch: 2, loss: 0.00102, speed: 2.06 step/s\r\n",
      "global step 400, epoch: 2, loss: 0.00101, speed: 2.05 step/s\r\n",
      "[2023-01-28 13:52:46,800] [    INFO] - Configuration saved in ./checkpoint/model_400/config.json\r\n",
      "[2023-01-28 13:52:47,660] [    INFO] - tokenizer config file saved in ./checkpoint/model_400/tokenizer_config.json\r\n",
      "[2023-01-28 13:52:47,660] [    INFO] - Special tokens file saved in ./checkpoint/model_400/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.82it/s]\r\n",
      "Evaluation precision: 0.90832, recall: 0.87295, F1: 0.89028\r\n",
      "best F1 performence has been updated: 0.87866 --> 0.89028\r\n",
      "[2023-01-28 13:52:54,725] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:52:58,494] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:52:58,494] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 410, epoch: 2, loss: 0.00100, speed: 2.05 step/s\r\n",
      "global step 420, epoch: 2, loss: 0.00099, speed: 2.05 step/s\r\n",
      "global step 430, epoch: 2, loss: 0.00098, speed: 2.04 step/s\r\n",
      "global step 440, epoch: 2, loss: 0.00098, speed: 2.05 step/s\r\n",
      "global step 450, epoch: 2, loss: 0.00097, speed: 2.06 step/s\r\n",
      "global step 460, epoch: 2, loss: 0.00095, speed: 2.04 step/s\r\n",
      "global step 470, epoch: 2, loss: 0.00095, speed: 2.05 step/s\r\n",
      "global step 480, epoch: 2, loss: 0.00095, speed: 2.05 step/s\r\n",
      "global step 490, epoch: 2, loss: 0.00094, speed: 2.06 step/s\r\n",
      "global step 500, epoch: 2, loss: 0.00093, speed: 2.04 step/s\r\n",
      "[2023-01-28 13:53:47,280] [    INFO] - Configuration saved in ./checkpoint/model_500/config.json\r\n",
      "[2023-01-28 13:53:48,141] [    INFO] - tokenizer config file saved in ./checkpoint/model_500/tokenizer_config.json\r\n",
      "[2023-01-28 13:53:48,141] [    INFO] - Special tokens file saved in ./checkpoint/model_500/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.83it/s]\r\n",
      "Evaluation precision: 0.91525, recall: 0.88525, F1: 0.90000\r\n",
      "best F1 performence has been updated: 0.89028 --> 0.90000\r\n",
      "[2023-01-28 13:53:55,184] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:53:58,948] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:53:58,948] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 510, epoch: 2, loss: 0.00093, speed: 2.05 step/s\r\n",
      "global step 520, epoch: 2, loss: 0.00092, speed: 2.10 step/s\r\n",
      "global step 530, epoch: 3, loss: 0.00092, speed: 2.07 step/s\r\n",
      "global step 540, epoch: 3, loss: 0.00091, speed: 2.05 step/s\r\n",
      "global step 550, epoch: 3, loss: 0.00090, speed: 2.05 step/s\r\n",
      "global step 560, epoch: 3, loss: 0.00089, speed: 2.06 step/s\r\n",
      "global step 570, epoch: 3, loss: 0.00089, speed: 2.06 step/s\r\n",
      "global step 580, epoch: 3, loss: 0.00088, speed: 2.05 step/s\r\n",
      "global step 590, epoch: 3, loss: 0.00087, speed: 2.06 step/s\r\n",
      "global step 600, epoch: 3, loss: 0.00086, speed: 2.05 step/s\r\n",
      "[2023-01-28 13:54:47,487] [    INFO] - Configuration saved in ./checkpoint/model_600/config.json\r\n",
      "[2023-01-28 13:54:48,343] [    INFO] - tokenizer config file saved in ./checkpoint/model_600/tokenizer_config.json\r\n",
      "[2023-01-28 13:54:48,343] [    INFO] - Special tokens file saved in ./checkpoint/model_600/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.81it/s]\r\n",
      "Evaluation precision: 0.92324, recall: 0.88730, F1: 0.90491\r\n",
      "best F1 performence has been updated: 0.90000 --> 0.90491\r\n",
      "[2023-01-28 13:54:55,423] [    INFO] - Configuration saved in ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:54:59,172] [    INFO] - tokenizer config file saved in ./checkpoint/model_best/tokenizer_config.json\r\n",
      "[2023-01-28 13:54:59,172] [    INFO] - Special tokens file saved in ./checkpoint/model_best/special_tokens_map.json\r\n",
      "global step 610, epoch: 3, loss: 0.00086, speed: 2.06 step/s\r\n",
      "global step 620, epoch: 3, loss: 0.00085, speed: 2.05 step/s\r\n",
      "global step 630, epoch: 3, loss: 0.00084, speed: 2.05 step/s\r\n",
      "global step 640, epoch: 3, loss: 0.00084, speed: 2.06 step/s\r\n",
      "global step 650, epoch: 3, loss: 0.00083, speed: 2.05 step/s\r\n",
      "global step 660, epoch: 3, loss: 0.00083, speed: 2.04 step/s\r\n",
      "global step 670, epoch: 3, loss: 0.00083, speed: 2.06 step/s\r\n",
      "global step 680, epoch: 3, loss: 0.00082, speed: 2.05 step/s\r\n",
      "global step 690, epoch: 3, loss: 0.00082, speed: 2.04 step/s\r\n",
      "global step 700, epoch: 3, loss: 0.00082, speed: 2.05 step/s\r\n",
      "[2023-01-28 13:55:47,921] [    INFO] - Configuration saved in ./checkpoint/model_700/config.json\r\n",
      "[2023-01-28 13:55:48,796] [    INFO] - tokenizer config file saved in ./checkpoint/model_700/tokenizer_config.json\r\n",
      "[2023-01-28 13:55:48,796] [    INFO] - Special tokens file saved in ./checkpoint/model_700/special_tokens_map.json\r\n",
      "100%|███████████████████████████████████████████| 34/34 [00:07<00:00,  4.82it/s]\r\n",
      "Evaluation precision: 0.91772, recall: 0.89139, F1: 0.90437\r\n",
      "global step 710, epoch: 3, loss: 0.00081, speed: 2.05 step/s\r\n",
      "global step 720, epoch: 3, loss: 0.00081, speed: 2.04 step/s\r\n",
      "global step 730, epoch: 3, loss: 0.00080, speed: 2.06 step/s\r\n",
      "global step 740, epoch: 3, loss: 0.00080, speed: 2.05 step/s\r\n",
      "global step 750, epoch: 3, loss: 0.00079, speed: 2.05 step/s\r\n",
      "global step 760, epoch: 3, loss: 0.00079, speed: 2.05 step/s\r\n",
      "global step 770, epoch: 3, loss: 0.00079, speed: 2.04 step/s\r\n",
      "global step 780, epoch: 3, loss: 0.00079, speed: 2.08 step/s\r\n"
     ]
    }
   ],
   "source": [
    "!python finetune.py \\\n",
    "  --train_path ./data/data184040/train.json \\\n",
    "  --dev_path ./data/data184040/dev.json \\\n",
    "  --save_dir ./checkpoint \\\n",
    "  --learning_rate 1e-5 \\\n",
    "  --batch_size 16 \\\n",
    "  --max_seq_len 512 \\\n",
    "  --num_epochs 3 \\\n",
    "  --model uie-senta-base \\\n",
    "  --seed 1000 \\\n",
    "  --logging_steps 10 \\\n",
    "  --valid_steps 100 \\\n",
    "  --device gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:56:37.392869Z",
     "iopub.status.busy": "2023-01-28T05:56:37.392477Z",
     "iopub.status.idle": "2023-01-28T05:56:52.383694Z",
     "shell.execute_reply": "2023-01-28T05:56:52.382561Z",
     "shell.execute_reply.started": "2023-01-28T05:56:37.392838Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:56:40,227] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load './checkpoint/model_best'.\r\n",
      "[2023-01-28 13:56:40,251] [    INFO] - loading configuration file ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:56:40,252] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"UIE\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"dtype\": \"float32\",\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "W0128 13:56:42.249591  2196 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2\r\n",
      "W0128 13:56:42.252538  2196 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2023-01-28 13:56:43,110] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n",
      "\r\n",
      "[2023-01-28 13:56:43,110] [    INFO] - All the weights of UIE were initialized from the model checkpoint at ./checkpoint/model_best.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n",
      "100%|███████████████████████████████████████████| 33/33 [00:07<00:00,  4.13it/s]\r\n",
      "-----------------------------\r\n",
      "Class Name: all_classes\r\n",
      "Evaluation Precision: 0.89693 | Recall: 0.89890 | F1: 0.89791\r\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py \\\n",
    "    --model_path ./checkpoint/model_best \\\n",
    "    --test_path ./data/data184040/test.json \\\n",
    "    --batch_size 16 \\\n",
    "    --max_seq_len 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 模型预测\n",
    "paddlenlp.Taskflow装载定制模型，通过task_path指定模型权重文件的路径，路径下需要包含训练好的模型权重文件model_state.pdparams。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-28T05:56:52.387112Z",
     "iopub.status.busy": "2023-01-28T05:56:52.386819Z",
     "iopub.status.idle": "2023-01-28T05:57:06.867273Z",
     "shell.execute_reply": "2023-01-28T05:57:06.866508Z",
     "shell.execute_reply.started": "2023-01-28T05:56:52.387086Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-01-28 13:56:52,390] [    INFO] - Downloading model_config.json from https://paddlenlp.bj.bcebos.com/taskflow/sentiment_analysis/uie-senta-base/model_config.json\r\n",
      "100%|██████████| 474/474 [00:00<00:00, 458kB/s]\r\n",
      "[2023-01-28 13:56:53,482] [    INFO] - loading configuration file ./checkpoint/model_best/config.json\r\n",
      "[2023-01-28 13:56:53,486] [    INFO] - Model config ErnieConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"UIE\"\r\n",
      "  ],\r\n",
      "  \"attention_probs_dropout_prob\": 0.1,\r\n",
      "  \"dtype\": \"float32\",\r\n",
      "  \"enable_recompute\": false,\r\n",
      "  \"fuse\": false,\r\n",
      "  \"hidden_act\": \"gelu\",\r\n",
      "  \"hidden_dropout_prob\": 0.1,\r\n",
      "  \"hidden_size\": 768,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 3072,\r\n",
      "  \"layer_norm_eps\": 1e-12,\r\n",
      "  \"max_position_embeddings\": 2048,\r\n",
      "  \"model_type\": \"ernie\",\r\n",
      "  \"num_attention_heads\": 12,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"paddlenlp_version\": null,\r\n",
      "  \"pool_act\": \"tanh\",\r\n",
      "  \"task_id\": 0,\r\n",
      "  \"task_type_vocab_size\": 3,\r\n",
      "  \"type_vocab_size\": 4,\r\n",
      "  \"use_task_id\": true,\r\n",
      "  \"vocab_size\": 40000\r\n",
      "}\r\n",
      "\r\n",
      "[2023-01-28 13:56:54,914] [    INFO] - All model checkpoint weights were used when initializing UIE.\r\n",
      "\r\n",
      "[2023-01-28 13:56:54,916] [    INFO] - All the weights of UIE were initialized from the model checkpoint at ./checkpoint/model_best.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\r\n",
      "[2023-01-28 13:56:54,920] [    INFO] - Converting to the inference model cost a little time.\r\n",
      "[2023-01-28 13:57:04,616] [    INFO] - The inference model save in the path:./checkpoint/model_best/static/inference\r\n",
      "[2023-01-28 13:57:06,624] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load './checkpoint/model_best'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'评价维度': [{'end': 24,\r\n",
      "            'probability': 0.6916713427446552,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9369049168239485,\r\n",
      "                                               'text': '负向'}],\r\n",
      "                          '观点词': [{'end': 26,\r\n",
      "                                   'probability': 0.7963797750248602,\r\n",
      "                                   'start': 24,\r\n",
      "                                   'text': '不好'}]},\r\n",
      "            'start': 22,\r\n",
      "            'text': '隔音'},\r\n",
      "           {'end': 6,\r\n",
      "            'probability': 0.9867240903472023,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9904469571051777,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 8,\r\n",
      "                                   'probability': 0.9974269681257226,\r\n",
      "                                   'start': 7,\r\n",
      "                                   'text': '大'}]},\r\n",
      "            'start': 4,\r\n",
      "            'text': '房间'},\r\n",
      "           {'end': 13,\r\n",
      "            'probability': 0.5167817218930431,\r\n",
      "            'relations': {'情感倾向[正向,负向,未提及]': [{'probability': 0.9969810469546623,\r\n",
      "                                               'text': '正向'}],\r\n",
      "                          '观点词': [{'end': 17,\r\n",
      "                                   'probability': 0.985259926709432,\r\n",
      "                                   'start': 15,\r\n",
      "                                   'text': '热情'}]},\r\n",
      "            'start': 9,\r\n",
      "            'text': '店家服务'}]}]\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from pprint import pprint\n",
    "\n",
    "schema = [{'评价维度': ['观点词', '情感倾向[正向,负向,未提及]']}]\n",
    "senta = Taskflow(\"sentiment_analysis\", model=\"uie-senta-base\", schema=schema, task_path=\"./checkpoint/model_best\")\n",
    "pprint(senta(\"这家点的房间很大，店家服务也很热情，就是房间隔音不好\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入交流群，一起学习吧\n",
    "更多信息请参考[PaddleNLP情感分析](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/sentiment_analysis/unified_sentiment_extraction)。 以上实现基于PaddleNLP，如有帮助，欢迎Star⭐支持~ \n",
    "\n",
    "GitHub地址：[https://github.com/PaddlePaddle/PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP)\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/7f287240b16f4c4081d0b57ca808dce62769b13369434c64b9a26cfc48b6a978\" width=\"80%\" height=\"80%\"> <br />\n",
    "\n",
    "- **加入交流群，一起创造吧**\n",
    "\n",
    "欢迎加入PaddleNLP**微信群**，交流更多前沿技术、调优经验。\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/926a029e46294158a6f4b244070f31c56690a62a84aa415d9a6930594c7af974\" width=\"25%\" height=\"25%\"> <br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
