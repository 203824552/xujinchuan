{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:56:27.054911Z",
     "iopub.status.busy": "2023-08-11T07:56:27.054227Z",
     "iopub.status.idle": "2023-08-11T07:56:29.440228Z",
     "shell.execute_reply": "2023-08-11T07:56:29.439288Z",
     "shell.execute_reply.started": "2023-08-11T07:56:27.054875Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: pip in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (22.1.2)\r\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\r\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T08:57:11.411530Z",
     "iopub.status.busy": "2023-08-11T08:57:11.410365Z",
     "iopub.status.idle": "2023-08-11T08:57:12.502940Z",
     "shell.execute_reply": "2023-08-11T08:57:12.501888Z",
     "shell.execute_reply.started": "2023-08-11T08:57:11.411499Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                        Version\r\n",
      "------------------------------ ---------------\r\n",
      "absl-py                        0.8.1\r\n",
      "aiofiles                       23.1.0\r\n",
      "aiohttp                        3.8.4\r\n",
      "aiosignal                      1.3.1\r\n",
      "alembic                        1.8.1\r\n",
      "altair                         4.2.2\r\n",
      "anyio                          3.6.1\r\n",
      "argon2-cffi                    21.3.0\r\n",
      "argon2-cffi-bindings           21.2.0\r\n",
      "aspy.yaml                      1.3.0\r\n",
      "astor                          0.8.1\r\n",
      "astroid                        2.4.1\r\n",
      "async-generator                1.10\r\n",
      "async-timeout                  4.0.2\r\n",
      "asynctest                      0.13.0\r\n",
      "attrs                          22.1.0\r\n",
      "audioread                      2.1.8\r\n",
      "autopep8                       1.6.0\r\n",
      "Babel                          2.8.0\r\n",
      "backcall                       0.1.0\r\n",
      "backports.zoneinfo             0.2.1\r\n",
      "bce-python-sdk                 0.8.53\r\n",
      "beautifulsoup4                 4.11.1\r\n",
      "bleach                         5.0.1\r\n",
      "blinker                        1.5\r\n",
      "cachetools                     4.0.0\r\n",
      "certifi                        2019.9.11\r\n",
      "certipy                        0.1.3\r\n",
      "cffi                           1.15.1\r\n",
      "cfgv                           2.0.1\r\n",
      "chardet                        3.0.4\r\n",
      "charset-normalizer             3.1.0\r\n",
      "Click                          7.0\r\n",
      "cloudpickle                    1.6.0\r\n",
      "cma                            2.7.0\r\n",
      "colorama                       0.4.4\r\n",
      "colorlog                       4.1.0\r\n",
      "cryptography                   38.0.1\r\n",
      "cycler                         0.10.0\r\n",
      "Cython                         0.29\r\n",
      "debugpy                        1.6.0\r\n",
      "decorator                      4.4.2\r\n",
      "defusedxml                     0.7.1\r\n",
      "dill                           0.3.3\r\n",
      "easydict                       1.9\r\n",
      "entrypoints                    0.4\r\n",
      "et-xmlfile                     1.0.1\r\n",
      "fastapi                        0.95.0\r\n",
      "fastjsonschema                 2.16.1\r\n",
      "ffmpy                          0.3.0\r\n",
      "filelock                       3.0.12\r\n",
      "flake8                         4.0.1\r\n",
      "Flask                          1.1.1\r\n",
      "Flask-Babel                    1.0.0\r\n",
      "Flask-Cors                     3.0.8\r\n",
      "forbiddenfruit                 0.1.3\r\n",
      "frozenlist                     1.3.3\r\n",
      "fsspec                         2023.1.0\r\n",
      "funcsigs                       1.0.2\r\n",
      "future                         0.18.0\r\n",
      "gast                           0.3.3\r\n",
      "gitdb                          4.0.5\r\n",
      "GitPython                      3.1.14\r\n",
      "google-auth                    1.10.0\r\n",
      "google-auth-oauthlib           0.4.1\r\n",
      "gradio                         3.19.1\r\n",
      "graphviz                       0.13\r\n",
      "greenlet                       1.1.3\r\n",
      "grpcio                         1.35.0\r\n",
      "gunicorn                       20.0.4\r\n",
      "gym                            0.12.1\r\n",
      "h11                            0.14.0\r\n",
      "h5py                           2.9.0\r\n",
      "httpcore                       0.16.3\r\n",
      "httpx                          0.23.3\r\n",
      "identify                       1.4.10\r\n",
      "idna                           2.8\r\n",
      "imageio                        2.6.1\r\n",
      "imageio-ffmpeg                 0.3.0\r\n",
      "importlib-metadata             4.2.0\r\n",
      "importlib-resources            5.9.0\r\n",
      "ipykernel                      6.9.1\r\n",
      "ipython                        7.34.0\r\n",
      "ipython-genutils               0.2.0\r\n",
      "ipywidgets                     7.6.5\r\n",
      "isort                          4.3.21\r\n",
      "itsdangerous                   1.1.0\r\n",
      "jdcal                          1.4.1\r\n",
      "jedi                           0.17.2\r\n",
      "jieba                          0.42.1\r\n",
      "Jinja2                         3.0.0\r\n",
      "joblib                         0.14.1\r\n",
      "JPype1                         0.7.2\r\n",
      "json5                          0.9.5\r\n",
      "jsonschema                     4.16.0\r\n",
      "jupyter-archive                3.2.1\r\n",
      "jupyter_client                 7.3.5\r\n",
      "jupyter-core                   4.11.1\r\n",
      "jupyter-lsp                    1.5.1\r\n",
      "jupyter-server                 1.16.0\r\n",
      "jupyter-telemetry              0.1.0\r\n",
      "jupyterhub                     1.3.0\r\n",
      "jupyterlab                     3.4.5\r\n",
      "jupyterlab-language-pack-zh-CN 3.4.post1\r\n",
      "jupyterlab-pygments            0.2.2\r\n",
      "jupyterlab-server              2.10.3\r\n",
      "jupyterlab-widgets             3.0.3\r\n",
      "kiwisolver                     1.1.0\r\n",
      "lazy-object-proxy              1.4.3\r\n",
      "librosa                        0.7.2\r\n",
      "lightgbm                       3.1.1\r\n",
      "linkify-it-py                  2.0.0\r\n",
      "llvmlite                       0.31.0\r\n",
      "lxml                           4.9.1\r\n",
      "Mako                           1.2.2\r\n",
      "Markdown                       3.1.1\r\n",
      "markdown-it-py                 2.2.0\r\n",
      "MarkupSafe                     2.0.1\r\n",
      "matplotlib                     2.2.3\r\n",
      "matplotlib-inline              0.1.6\r\n",
      "mccabe                         0.6.1\r\n",
      "mdit-py-plugins                0.3.3\r\n",
      "mdurl                          0.1.1\r\n",
      "mistune                        0.8.4\r\n",
      "more-itertools                 7.2.0\r\n",
      "moviepy                        1.0.1\r\n",
      "multidict                      6.0.4\r\n",
      "multiprocess                   0.70.11.1\r\n",
      "nbclassic                      0.3.1\r\n",
      "nbclient                       0.5.13\r\n",
      "nbconvert                      6.4.4\r\n",
      "nbformat                       5.5.0\r\n",
      "nest-asyncio                   1.5.5\r\n",
      "netifaces                      0.10.9\r\n",
      "networkx                       2.4\r\n",
      "nltk                           3.4.5\r\n",
      "nodeenv                        1.3.4\r\n",
      "notebook                       5.7.8\r\n",
      "numba                          0.48.0\r\n",
      "numpy                          1.19.5\r\n",
      "oauthlib                       3.1.0\r\n",
      "objgraph                       3.4.1\r\n",
      "opencv-python                  4.1.1.26\r\n",
      "openpyxl                       3.0.5\r\n",
      "opt-einsum                     3.3.0\r\n",
      "orjson                         3.8.7\r\n",
      "packaging                      21.3\r\n",
      "paddle-bfloat                  0.1.7\r\n",
      "paddle2onnx                    1.0.0\r\n",
      "paddlefsl                      1.0.0\r\n",
      "paddlehub                      2.3.0\r\n",
      "paddlenlp                      2.1.1\r\n",
      "paddlepaddle                   2.3.2\r\n",
      "pamela                         1.0.0\r\n",
      "pandas                         1.1.5\r\n",
      "pandocfilters                  1.5.0\r\n",
      "parl                           1.4.1\r\n",
      "parso                          0.7.1\r\n",
      "pathlib                        1.0.1\r\n",
      "pexpect                        4.7.0\r\n",
      "pickleshare                    0.7.5\r\n",
      "Pillow                         8.2.0\r\n",
      "pip                            22.1.2\r\n",
      "pkgutil_resolve_name           1.3.10\r\n",
      "plotly                         5.8.0\r\n",
      "pluggy                         1.0.0\r\n",
      "pre-commit                     1.21.0\r\n",
      "prettytable                    0.7.2\r\n",
      "proglog                        0.1.9\r\n",
      "prometheus-client              0.14.1\r\n",
      "prompt-toolkit                 2.0.10\r\n",
      "protobuf                       3.20.0\r\n",
      "psutil                         5.7.2\r\n",
      "ptyprocess                     0.7.0\r\n",
      "py4j                           0.10.9.2\r\n",
      "pyarrow                        11.0.0\r\n",
      "pyasn1                         0.4.8\r\n",
      "pyasn1-modules                 0.2.7\r\n",
      "pycodestyle                    2.8.0\r\n",
      "pycparser                      2.21\r\n",
      "pycryptodome                   3.9.9\r\n",
      "pydantic                       1.10.6\r\n",
      "pydeck                         0.8.0\r\n",
      "pydocstyle                     5.0.2\r\n",
      "pydub                          0.25.1\r\n",
      "pyflakes                       2.4.0\r\n",
      "pyglet                         1.4.5\r\n",
      "Pygments                       2.13.0\r\n",
      "pylint                         2.5.2\r\n",
      "Pympler                        1.0.1\r\n",
      "pynvml                         8.0.4\r\n",
      "pyOpenSSL                      22.0.0\r\n",
      "pyparsing                      3.0.9\r\n",
      "pypmml                         0.9.11\r\n",
      "pyrsistent                     0.18.1\r\n",
      "python-dateutil                2.8.2\r\n",
      "python-json-logger             2.0.4\r\n",
      "python-jsonrpc-server          0.3.4\r\n",
      "python-language-server         0.33.0\r\n",
      "python-lsp-jsonrpc             1.0.0\r\n",
      "python-lsp-server              1.5.0\r\n",
      "python-multipart               0.0.6\r\n",
      "pytz                           2019.3\r\n",
      "pytz-deprecation-shim          0.1.0.post0\r\n",
      "PyYAML                         5.1.2\r\n",
      "pyzmq                          23.2.1\r\n",
      "rarfile                        3.1\r\n",
      "recordio                       0.1.7\r\n",
      "requests                       2.24.0\r\n",
      "requests-oauthlib              1.3.0\r\n",
      "resampy                        0.2.2\r\n",
      "rfc3986                        1.5.0\r\n",
      "rich                           13.3.2\r\n",
      "rope                           0.17.0\r\n",
      "rsa                            4.0\r\n",
      "ruamel.yaml                    0.17.21\r\n",
      "ruamel.yaml.clib               0.2.6\r\n",
      "scikit-learn                   0.22.1\r\n",
      "scipy                          1.3.0\r\n",
      "seaborn                        0.10.0\r\n",
      "semver                         2.13.0\r\n",
      "Send2Trash                     1.8.0\r\n",
      "sentencepiece                  0.1.96\r\n",
      "seqeval                        1.2.2\r\n",
      "setuptools                     41.4.0\r\n",
      "shellcheck-py                  0.7.1.1\r\n",
      "six                            1.16.0\r\n",
      "sklearn                        0.0\r\n",
      "smmap                          3.0.5\r\n",
      "sniffio                        1.3.0\r\n",
      "snowballstemmer                2.0.0\r\n",
      "SoundFile                      0.10.3.post1\r\n",
      "soupsieve                      2.3.2.post1\r\n",
      "SQLAlchemy                     1.4.41\r\n",
      "starlette                      0.26.1\r\n",
      "streamlit                      1.13.0\r\n",
      "streamlit-image-comparison     0.0.4\r\n",
      "tabulate                       0.8.3\r\n",
      "tb-nightly                     1.15.0a20190801\r\n",
      "tb-paddle                      0.3.6\r\n",
      "tenacity                       8.0.1\r\n",
      "tensorboard                    2.1.0\r\n",
      "tensorboardX                   1.8\r\n",
      "termcolor                      1.1.0\r\n",
      "terminado                      0.15.0\r\n",
      "testpath                       0.4.2\r\n",
      "tinycss2                       1.1.1\r\n",
      "toml                           0.10.0\r\n",
      "toolz                          0.12.0\r\n",
      "tornado                        6.2\r\n",
      "tqdm                           4.27.0\r\n",
      "traitlets                      5.4.0\r\n",
      "typed-ast                      1.4.1\r\n",
      "typing_extensions              4.3.0\r\n",
      "tzdata                         2022.7\r\n",
      "tzlocal                        4.3\r\n",
      "uc-micro-py                    1.0.1\r\n",
      "ujson                          1.35\r\n",
      "urllib3                        1.25.6\r\n",
      "uvicorn                        0.21.1\r\n",
      "validators                     0.20.0\r\n",
      "virtualenv                     16.7.9\r\n",
      "visualdl                       2.4.0\r\n",
      "watchdog                       2.3.1\r\n",
      "wcwidth                        0.1.7\r\n",
      "webencodings                   0.5.1\r\n",
      "websocket-client               1.4.1\r\n",
      "websockets                     10.4\r\n",
      "Werkzeug                       0.16.0\r\n",
      "whatthepatch                   1.0.2\r\n",
      "wheel                          0.33.6\r\n",
      "widgetsnbextension             3.5.2\r\n",
      "wrapt                          1.12.1\r\n",
      "xarray                         0.16.2\r\n",
      "xgboost                        1.3.3\r\n",
      "xlrd                           1.2.0\r\n",
      "yapf                           0.26.0\r\n",
      "yarl                           1.8.2\r\n",
      "zipp                           3.8.1\r\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:48:44.336924Z",
     "iopub.status.busy": "2023-08-11T07:48:44.336292Z",
     "iopub.status.idle": "2023-08-11T07:48:46.744438Z",
     "shell.execute_reply": "2023-08-11T07:48:46.743432Z",
     "shell.execute_reply.started": "2023-08-11T07:48:44.336879Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.1.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\r\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\r\n",
      "Requirement already satisfied: paddlefsl==1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.0.0)\r\n",
      "Requirement already satisfied: pillow==8.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlefsl==1.0.0->paddlenlp) (8.2.0)\r\n",
      "Requirement already satisfied: requests~=2.24.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlefsl==1.0.0->paddlenlp) (2.24.0)\r\n",
      "Requirement already satisfied: tqdm~=4.27.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlefsl==1.0.0->paddlenlp) (4.27.0)\r\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlefsl==1.0.0->paddlenlp) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.16.0)\r\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2.8)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests~=2.24.0->paddlefsl==1.0.0->paddlenlp) (1.25.6)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\r\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 首先通过如下命令安装最新版本的 paddlenlp\n",
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:01:17.639178Z",
     "iopub.status.busy": "2024-08-06T08:01:17.638175Z",
     "iopub.status.idle": "2024-08-06T08:01:21.608612Z",
     "shell.execute_reply": "2024-08-06T08:01:21.607455Z",
     "shell.execute_reply.started": "2024-08-06T08:01:17.639126Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "import abc\n",
    "import sys\n",
    "from functools import partial\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "# 导入python的其他库\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from scipy.special import softmax\n",
    "from scipy.special import expit\n",
    "# 导入Paddle库\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle import inference\n",
    "\n",
    "#导入PaddleNLP相关的库\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset, MapDataset\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "from paddlenlp.utils.downloader import get_path_from_url\n",
    "from visualdl import LogWriter\n",
    "from data import convert_pairwise_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:01:28.701985Z",
     "iopub.status.busy": "2024-08-06T08:01:28.701366Z",
     "iopub.status.idle": "2024-08-06T08:01:28.748762Z",
     "shell.execute_reply": "2024-08-06T08:01:28.747735Z",
     "shell.execute_reply.started": "2024-08-06T08:01:28.701942Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_a': '异质性机构投资者、公司治理与信息披露', 'text_b': '异质性机构投资者、公司治理与信息披露'}\r\n",
      "{'text_a': '广东省新型冠状病毒肺炎中医药治疗方案', 'text_b': '广东省新型冠状病毒肺炎中医药治疗方案'}\r\n",
      "{'text_a': '\"光伏并网逆变器模糊准 PR 控制仿真研究单相并网逆变器,电流控制,准 PR 控制,模糊控制\"', 'text_b': '\"光伏并网逆变器模糊准 PR 控制仿真研究单相并网逆变器,电流控制,准 PR 控制,模糊控制\"'}\r\n",
      "{'text_a': '\"脱镁叶绿酸a甲酯衍生物的合成脱镁叶绿酸a甲酯,加成反应,氧化反应,合成\"', 'text_b': '\"脱镁叶绿酸a甲酯衍生物的合成脱镁叶绿酸a甲酯,加成反应,氧化反应,合成\"'}\r\n",
      "{'text_a': '\"探讨超声检查诊断单纯性单侧多囊性发育不良肾的价值超声检查诊断,单纯性,单侧多囊性发育不良肾,MCDK,诊断价值\"', 'text_b': '\"探讨超声检查诊断单纯性单侧多囊性发育不良肾的价值超声检查诊断,单纯性,单侧多囊性发育不良肾,MCDK,诊断价值\"'}\r\n"
     ]
    }
   ],
   "source": [
    "# 数据读取逻辑\n",
    "def read_simcse_text(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if(i==0):\n",
    "                continue\n",
    "            data = line.rstrip()\n",
    "            # 这里的text_a和text_b是一样的\n",
    "            yield {'text_a': data, 'text_b': data}\n",
    "\n",
    "train_set_file='train_demo.csv'\n",
    "train_ds = load_dataset(read_simcse_text, data_path=train_set_file, lazy=False)\n",
    "# 展示3条数据\n",
    "for i  in range(5):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:48:49.050202Z",
     "iopub.status.busy": "2023-08-11T07:48:49.049868Z",
     "iopub.status.idle": "2023-08-11T07:48:49.070297Z",
     "shell.execute_reply": "2023-08-11T07:48:49.069634Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.050177Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Data: \r\n",
      " [[1 2 3 4]\r\n",
      " [5 6 7 0]\r\n",
      " [8 9 0 0]]\r\n",
      "\r\n",
      "Stacked Data: \r\n",
      " [[1 2 3 4]\r\n",
      " [3 4 5 6]\r\n",
      " [5 6 7 8]]\r\n",
      "\r\n",
      "ids: \r\n",
      " [[1 2 3 4]\r\n",
      " [5 6 7 0]\r\n",
      " [8 9 0 0]]\r\n",
      "\r\n",
      "labels: \r\n",
      " [[1]\r\n",
      " [0]\r\n",
      " [1]]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 由于文本是序列数据，数据对齐。如下面会对每个序列补0，和a的长度保持一致\n",
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7]\n",
    "c = [8, 9]\n",
    "result = Pad(pad_val=0)([a, b, c])\n",
    "print(\"Padded Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "# 组装minibatch需要使用\n",
    "a = [1, 2, 3, 4]\n",
    "b = [3, 4, 5, 6]\n",
    "c = [5, 6, 7, 8]\n",
    "result = Stack()([a, b, c])\n",
    "print(\"Stacked Data: \\n\", result)\n",
    "print()\n",
    "\n",
    "data = [\n",
    "        [[1, 2, 3, 4], [1]],\n",
    "        [[5, 6, 7], [0]],\n",
    "        [[8, 9], [1]],\n",
    "       ]\n",
    "batchify_fn = Tuple(Pad(pad_val=0), Stack())\n",
    "ids, labels = batchify_fn(data)\n",
    "print(\"ids: \\n\", ids)\n",
    "print()\n",
    "print(\"labels: \\n\", labels)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T07:49:24.182738Z",
     "iopub.status.busy": "2023-08-11T07:49:24.181739Z",
     "iopub.status.idle": "2023-08-11T07:49:24.277817Z",
     "shell.execute_reply": "2023-08-11T07:49:24.276752Z",
     "shell.execute_reply.started": "2023-08-11T07:49:24.182691Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-08-11 15:49:24,190] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/community/ernie-3.0-medium-zh/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh\r\n",
      "[2023-08-11 15:49:24,193] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/community/ernie-3.0-medium-zh/vocab.txt\r\n",
      "[2023-08-11 15:49:24,255] [   ERROR] - Downloading from https://paddlenlp.bj.bcebos.com/models/transformers/community/ernie-3.0-medium-zh/vocab.txt failed with code 404!\r\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't load tokenizer for 'ernie-3.0-medium-zh'.\nPlease make sure that 'ernie-3.0-medium-zh' is:\n- a correct model-identifier of built-in pretrained models,\n- or a correct model-identifier of community-contributed pretrained models,\n- or the correct path to a directory containing relevant tokenizer files.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m                     resolved_vocab_files[file_id] = get_path_from_url(\n\u001b[0;32m--> 543\u001b[0;31m                         file_path, default_root)\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/utils/downloader.py\u001b[0m in \u001b[0;36mget_path_from_url\u001b[0;34m(url, root_dir, md5sum, check_exist)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mParallelEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfullpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/utils/downloader.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(url, path, md5sum)\u001b[0m\n\u001b[1;32m    204\u001b[0m             raise RuntimeError(\"Downloading from {} failed with code \"\n\u001b[0;32m--> 205\u001b[0;31m                                \"{}!\".format(url, req.status_code))\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Downloading from https://paddlenlp.bj.bcebos.com/models/transformers/community/ernie-3.0-medium-zh/vocab.txt failed with code 404!",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_221/1875528063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# 根据经验 batch_size越大效果越好\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErnieTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ernie-3.0-medium-zh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;31m# 给convert_example赋予默认的值，如tokenizer，max_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m trans_func = partial(\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlenlp/transformers/tokenizer_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     raise RuntimeError(\n\u001b[0;32m--> 547\u001b[0;31m                         \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                         \u001b[0;34mf\"Please make sure that '{pretrained_model_name_or_path}' is:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                         \u001b[0;34m\"- a correct model-identifier of built-in pretrained models,\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't load tokenizer for 'ernie-3.0-medium-zh'.\nPlease make sure that 'ernie-3.0-medium-zh' is:\n- a correct model-identifier of built-in pretrained models,\n- or a correct model-identifier of community-contributed pretrained models,\n- or the correct path to a directory containing relevant tokenizer files.\n"
     ]
    }
   ],
   "source": [
    "# 明文数据 -> ID 序列训练数据\n",
    "\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    if mode == 'train':\n",
    "        # 分布式批采样器加载数据的一个子集。\n",
    "        # 每个进程可以传递给DataLoader一个DistributedBatchSampler的实例，每个进程加载原始数据的一个子集。\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        # 批采样器的基础实现，\n",
    "        # 用于 paddle.io.DataLoader 中迭代式获取mini-batch的样本下标数组，数组长度与 batch_size 一致。\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    # 组装mini-batch\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)\n",
    "\n",
    "def convert_example(example, tokenizer, max_seq_length=512, do_evalute=False):\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for key, text in example.items():\n",
    "        if 'label' in key:\n",
    "            # do_evaluate\n",
    "            result += [example['label']]\n",
    "        else:\n",
    "            # do_train\n",
    "            encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "            input_ids = encoded_inputs[\"input_ids\"]\n",
    "            token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "            result += [input_ids, token_type_ids]\n",
    "\n",
    "    return result\n",
    "\n",
    "# 语义索引的维度最大为64，可以根据自己的情况调节长度\n",
    "max_seq_length=64\n",
    "# 根据经验 batch_size越大效果越好\n",
    "batch_size=32\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-3.0-medium-zh')\n",
    "# 给convert_example赋予默认的值，如tokenizer，max_seq_length\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# [pad]对齐的函数\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # query_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # query_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # title_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # tilte_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# 构建训练的Dataloader\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示一下输入的dataloader的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.245534Z",
     "iopub.status.idle": "2023-08-11T07:48:49.245861Z",
     "shell.execute_reply": "2023-08-11T07:48:49.245719Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.245704Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(train_data_loader):\n",
    "    if idx == 0:\n",
    "        print(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.247302Z",
     "iopub.status.idle": "2023-08-11T07:48:49.247624Z",
     "shell.execute_reply": "2023-08-11T07:48:49.247474Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.247460Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCSE(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.0,\n",
    "                 scale=20,\n",
    "                 output_emb_size=None):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptm = pretrained_model\n",
    "        # 显式的加一个dropout来控制\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "\n",
    "        # if output_emb_size is greater than 0, then add Linear layer to reduce embedding_size, \n",
    "        # 考虑到性能和效率，我们推荐把output_emb_size设置成256\n",
    "        # 向量越大，语义信息越丰富，但消耗资源越多\n",
    "        self.output_emb_size = output_emb_size\n",
    "        if output_emb_size > 0:\n",
    "            weight_attr = paddle.ParamAttr(\n",
    "                initializer=nn.initializer.TruncatedNormal(std=0.02))\n",
    "            self.emb_reduce_linear = paddle.nn.Linear(\n",
    "                768, output_emb_size, weight_attr=weight_attr)\n",
    "\n",
    "        self.margin = margin\n",
    "        # 为了使余弦相似度更容易收敛，我们选择把计算出来的余弦相似度扩大scale倍，一般设置成20左右\n",
    "        self.sacle = scale\n",
    "\n",
    "    # 加入jit注释能够把该提取向量的函数导出成静态图\n",
    "    # 对应input_id,token_type_id两个\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None,\n",
    "                             with_pooler=True):\n",
    "\n",
    "        # Note: cls_embedding is poolerd embedding with act tanh \n",
    "        sequence_output, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                                  position_ids, attention_mask)\n",
    "\n",
    "        if with_pooler == False:\n",
    "            cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        if self.output_emb_size > 0:\n",
    "            cls_embedding = self.emb_reduce_linear(cls_embedding)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/nn/functional/normalize_cn.html\n",
    "        cls_embedding = F.normalize(cls_embedding, p=2, axis=-1)\n",
    "        return cls_embedding\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "        \n",
    "        # 第 1 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        # 第 2 次编码: 文本经过无监督语义索引模型编码后的语义向量 \n",
    "        # [N, 768]\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        # 相似度矩阵: [N, N]\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        # 填充self.margin值，比如margin为0.2，query_cls_embedding.shape[0]=2 \n",
    "        # margin_diag: [0.2,0.2]\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "        # input paddle.diag(margin_diag): [[0.2,0],[0,0.2]]\n",
    "        # input cosine_sim : [[1.0,0.6],[0.6,1.0]]\n",
    "        # output cosine_sim: [[0.8,0.6],[0.6,0.8]]\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        # 转化成多分类任务: 对角线元素是正例，其余元素为负例\n",
    "        # labels : [0,1,2,3]\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        # labels : [[0],[1],[2],[3]]\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        # 交叉熵损失函数\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练配置\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.248312Z",
     "iopub.status.idle": "2023-08-11T07:48:49.248615Z",
     "shell.execute_reply": "2023-08-11T07:48:49.248472Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.248459Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# SimCSE的dropout的参数，也可以使用预训练语言模型默认的dropout参数\n",
    "dropout=0.2\n",
    "# 向量映射的维度，默认的输出是768维，推荐通过线性层映射成256维\n",
    "output_emb_size=256\n",
    "# 训练的epoch数目\n",
    "epochs=1\n",
    "weight_decay=0.0\n",
    "# 学习率\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练模型\n",
    "1. 加载预训练模型 ERNIE 3.0-Medium 进行热启\n",
    "2. 定义优化器 AdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.249681Z",
     "iopub.status.idle": "2023-08-11T07:48:49.249991Z",
     "shell.execute_reply": "2023-08-11T07:48:49.249844Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.249830Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置 ERNIE-3.0-Medium-zh 预训练模型\n",
    "model_name_or_path='ernie-3.0-medium-zh'\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "       model_name_or_path,\n",
    "       hidden_dropout_prob=dropout,\n",
    "       attention_probs_dropout_prob=dropout)\n",
    "print(\"loading model from {}\".format(model_name_or_path))\n",
    "\n",
    "# 实例化SimCSE，SimCSE使用的Encoder是ERNIE-3.0-Medium-zh\n",
    "model = SimCSE(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "# 训练的总步数\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "# warmpup操作，学习率先上升后下降\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "# 设置优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练\n",
    "\n",
    "上面的训练配置完毕以后，下面就可以开始训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.250926Z",
     "iopub.status.idle": "2023-08-11T07:48:49.251222Z",
     "shell.execute_reply": "2023-08-11T07:48:49.251085Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.251072Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir='checkpoint'\n",
    "save_steps=100\n",
    "time_start=time.time()\n",
    "global_step = 0\n",
    "tic_train = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "        # 其中query和title为同一条数据\n",
    "        loss = model(\n",
    "                query_input_ids=query_input_ids,\n",
    "                title_input_ids=title_input_ids,\n",
    "                query_token_type_ids=query_token_type_ids,\n",
    "                title_token_type_ids=title_token_type_ids)\n",
    "        # 每隔10个step进行打印日志\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        # 反向\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "        # 每隔save_steps保存模型\n",
    "        if global_step % save_steps == 0:\n",
    "            save_path = os.path.join(save_dir, \"model_%d\" % (global_step))\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path)\n",
    "            save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "            paddle.save(model.state_dict(), save_param_path)\n",
    "            tokenizer.save_pretrained(save_path)\n",
    "time_end=time.time()\n",
    "print('totally cost {} seconds'.format(time_end-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型预测\n",
    "\n",
    "由于本项目使用的demo数据，在预测部分为了保证效果，我们使用已经用全量数据训练好的模型，首先下载训练好的SimCSE模型，然后进行解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.252223Z",
     "iopub.status.idle": "2023-08-11T07:48:49.252527Z",
     "shell.execute_reply": "2023-08-11T07:48:49.252382Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.252370Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists('simcse_model.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/simcse_model.zip',root_dir='.')\n",
    "# 解压SimCSE模型\n",
    "!unzip -o simcse_model.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.253389Z",
     "iopub.status.idle": "2023-08-11T07:48:49.253696Z",
     "shell.execute_reply": "2023-08-11T07:48:49.253558Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.253545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import convert_example_test\n",
    "\n",
    "# 加载预训练好的无监督语义索引模型 SimCSE\n",
    "params_path='pretrained/model_20000/model_state.pdparams'\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "# 定义两条文本数据\n",
    "test_data = ['国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据', '语义检索相关的论文']\n",
    "# 给convert_example_test赋予默认值\n",
    "test_func = partial(\n",
    "        convert_example_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "# pad对齐操作\n",
    "test_batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # text_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # text_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# conver_example function's input must be dict\n",
    "corpus_ds = MapDataset(test_data)\n",
    "# 构造Dataloader\n",
    "corpus_data_loader = create_dataloader(\n",
    "        corpus_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=test_batchify_fn,\n",
    "        trans_fn=test_func)\n",
    "\n",
    "all_embeddings = []\n",
    "# 切换成eval模式，固定住 dropout\n",
    "model.eval()\n",
    "# 预测的时候不保存梯度\n",
    "with paddle.no_grad():\n",
    "    for batch_data in corpus_data_loader:\n",
    "        input_ids, token_type_ids = batch_data\n",
    "        input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "        # 抽取向量\n",
    "        text_embeddings = model.get_pooled_embedding(input_ids, token_type_ids)\n",
    "        all_embeddings.append(text_embeddings)\n",
    "\n",
    "text_embedding=all_embeddings[0]\n",
    "print(text_embedding.shape)\n",
    "print(text_embedding.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从输出结果可以看出，两条文本被抽取成了2条256维度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:03:20.512186Z",
     "iopub.status.busy": "2024-08-06T08:03:20.511533Z",
     "iopub.status.idle": "2024-08-06T08:03:20.606477Z",
     "shell.execute_reply": "2024-08-06T08:03:20.605529Z",
     "shell.execute_reply.started": "2024-08-06T08:03:20.512145Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_a': '从《唐律疏义》看唐代封爵贵族的法律特权', 'text_b': '从《唐律疏义》看唐代封爵贵族的法律特权《唐律疏义》,封爵贵族,法律特权'}\r\n",
      "{'text_a': '宁夏社区图书馆服务体系布局现状分析', 'text_b': '宁夏社区图书馆服务体系布局现状分析社区图书馆,社区图书馆服务,社区图书馆服务体系'}\r\n",
      "{'text_a': '人口老龄化对京津冀经济', 'text_b': '京津冀人口老龄化对区域经济增长的影响京津冀,人口老龄化,区域经济增长,固定效应模型'}\r\n"
     ]
    }
   ],
   "source": [
    "def read_text_pair(data_path):\n",
    "    \"\"\"Reads data.\"\"\"\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = line.rstrip().split(\"\\t\")\n",
    "            if len(data) != 2:\n",
    "                continue\n",
    "            # 可以看到有监督数据使用query title pair的\n",
    "            # 所以text_a和text_b不一样\n",
    "            yield {'text_a': data[0], 'text_b': data[1]}\n",
    "\n",
    "train_set_file='train.csv'\n",
    "train_ds = load_dataset(\n",
    "        read_text_pair, data_path=train_set_file, lazy=False)\n",
    "# 打印3条文本\n",
    "for i in range(3):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:03:31.328041Z",
     "iopub.status.busy": "2024-08-06T08:03:31.326829Z",
     "iopub.status.idle": "2024-08-06T08:03:31.359452Z",
     "shell.execute_reply": "2024-08-06T08:03:31.358422Z",
     "shell.execute_reply.started": "2024-08-06T08:03:31.328000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from base_model import SemanticIndexBase\n",
    "\n",
    "class SemanticIndexBatchNeg(SemanticIndexBase):\n",
    "    def __init__(self,\n",
    "                 pretrained_model,\n",
    "                 dropout=None,\n",
    "                 margin=0.3,\n",
    "                 scale=30,\n",
    "                 output_emb_size=None):\n",
    "        super().__init__(pretrained_model, dropout, output_emb_size)\n",
    "\n",
    "        self.margin = margin\n",
    "        # Used scaling cosine similarity to ease converge\n",
    "        self.sacle = scale\n",
    "\n",
    "    def forward(self,\n",
    "                query_input_ids,\n",
    "                title_input_ids,\n",
    "                query_token_type_ids=None,\n",
    "                query_position_ids=None,\n",
    "                query_attention_mask=None,\n",
    "                title_token_type_ids=None,\n",
    "                title_position_ids=None,\n",
    "                title_attention_mask=None):\n",
    "\n",
    "        query_cls_embedding = self.get_pooled_embedding(\n",
    "            query_input_ids, query_token_type_ids, query_position_ids,\n",
    "            query_attention_mask)\n",
    "\n",
    "        title_cls_embedding = self.get_pooled_embedding(\n",
    "            title_input_ids, title_token_type_ids, title_position_ids,\n",
    "            title_attention_mask)\n",
    "\n",
    "        cosine_sim = paddle.matmul(\n",
    "            query_cls_embedding, title_cls_embedding, transpose_y=True)\n",
    "\n",
    "        # substract margin from all positive samples cosine_sim()\n",
    "        margin_diag = paddle.full(\n",
    "            shape=[query_cls_embedding.shape[0]],\n",
    "            fill_value=self.margin,\n",
    "            dtype=paddle.get_default_dtype())\n",
    "\n",
    "        cosine_sim = cosine_sim - paddle.diag(margin_diag)\n",
    "\n",
    "        # scale cosine to ease training converge\n",
    "        cosine_sim *= self.sacle\n",
    "\n",
    "        labels = paddle.arange(0, query_cls_embedding.shape[0], dtype='int64')\n",
    "        labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "\n",
    "        loss = F.cross_entropy(input=cosine_sim, label=labels)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练配置\n",
    "\n",
    "定义模型训练的超参，优化器等等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:03:35.916435Z",
     "iopub.status.busy": "2024-08-06T08:03:35.915531Z",
     "iopub.status.idle": "2024-08-06T08:03:35.923036Z",
     "shell.execute_reply": "2024-08-06T08:03:35.921534Z",
     "shell.execute_reply.started": "2024-08-06T08:03:35.916391Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "scale=20 # 推荐值: 10 ~ 30\n",
    "margin=0.1 # 推荐值: 0.0 ~ 0.2\n",
    "# 最大序列长度\n",
    "max_seq_length=64\n",
    "epochs=1\n",
    "learning_rate=5E-5\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_steps=10\n",
    "batch_size=64\n",
    "output_emb_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-3.0-medium-zh')\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length) \n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # query_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # query_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # title_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # tilte_segment\n",
    "    ): [data for data in fn(samples)]  \n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# Inbatch-Negatives\n",
    "model = SemanticIndexBatchNeg(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion) \n",
    "\n",
    "# Generate parameter names needed to perform weight decay.\n",
    "# All bias and LayerNorm parameters are excluded.\n",
    "decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_train(model,train_data_loader):\n",
    "    \n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            query_input_ids, query_token_type_ids, title_input_ids, title_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                query_input_ids=query_input_ids,\n",
    "                title_input_ids=title_input_ids,\n",
    "                query_token_type_ids=query_token_type_ids,\n",
    "                title_token_type_ids=title_token_type_ids)\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % 5 == 0:\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            if global_step % save_steps == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 模型预测\n",
    "\n",
    "模型预测部分加载训练好的模型，然后输入两条示例数据进行预测抽取向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.260919Z",
     "iopub.status.idle": "2023-08-11T07:48:49.261213Z",
     "shell.execute_reply": "2023-08-11T07:48:49.261080Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.261067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://bj.bcebos.com/v1/paddlenlp/models/inbatch_model.zip \n",
    "\n",
    "if(not os.path.exists('inbatch_model.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/inbatch_model.zip',root_dir='.')\n",
    "\n",
    "!unzip -o inbatch_model.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.262106Z",
     "iopub.status.idle": "2023-08-11T07:48:49.262441Z",
     "shell.execute_reply": "2023-08-11T07:48:49.262309Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.262296Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length=64\n",
    "output_emb_size=256\n",
    "batch_size=1\n",
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-1.0')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-1.0')\n",
    "model = SemanticIndexBatchNeg(\n",
    "        pretrained_model,\n",
    "        margin=margin,\n",
    "        scale=scale,\n",
    "        output_emb_size=output_emb_size)\n",
    "params_path='pretrained/model_40/model_state.pdparams'\n",
    "test_data = [\"国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据\"]\n",
    "# 加载模型\n",
    "state_dict = paddle.load(params_path)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "test_func = partial(\n",
    "        convert_example_test,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "test_batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # text_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # text_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "# conver_example function's input must be dict\n",
    "corpus_ds = MapDataset(test_data)\n",
    "\n",
    "corpus_data_loader = create_dataloader(\n",
    "        corpus_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=test_batchify_fn,\n",
    "        trans_fn=test_func)\n",
    "\n",
    "all_embeddings = []\n",
    "model.eval()\n",
    "with paddle.no_grad():\n",
    "    for batch_data in corpus_data_loader:\n",
    "        input_ids, token_type_ids = batch_data\n",
    "        input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "        token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "        text_embeddings = model.get_pooled_embedding(input_ids, token_type_ids)\n",
    "        all_embeddings.append(text_embeddings)\n",
    "\n",
    "text_embedding=all_embeddings[0]\n",
    "print(text_embedding.shape)\n",
    "print(text_embedding.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.263466Z",
     "iopub.status.idle": "2023-08-11T07:48:49.263769Z",
     "shell.execute_reply": "2023-08-11T07:48:49.263635Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.263622Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path='output/recall'\n",
    "model.eval()\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "paddle.jit.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:04:43.428336Z",
     "iopub.status.busy": "2024-08-06T08:04:43.427529Z",
     "iopub.status.idle": "2024-08-06T08:04:43.452589Z",
     "shell.execute_reply": "2024-08-06T08:04:43.451526Z",
     "shell.execute_reply.started": "2024-08-06T08:04:43.428288Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data import convert_example_recall_infer\n",
    "from scipy.special import softmax\n",
    "from scipy import spatial\n",
    "\n",
    "class RecallPredictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if args.enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(args.cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "\n",
    "\n",
    "    def extract_embedding(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer` \n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the feature vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_recall_infer(text, tokenizer)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        logits = self.output_handle.copy_to_cpu()\n",
    "        return logits\n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "        \"\"\"\n",
    "        Predicts the data labels.\n",
    "        Args:\n",
    "            data (obj:`List(str)`): The batch data whose each element is a raw text.\n",
    "            tokenizer(obj:`PretrainedTokenizer`): This tokenizer inherits from :class:`~paddlenlp.transformers.PretrainedTokenizer` \n",
    "                which contains most of the methods. Users should refer to the superclass for more information regarding methods.\n",
    "        Returns:\n",
    "            results(obj:`dict`): All the predictions probs.\n",
    "        \"\"\"\n",
    "\n",
    "        examples = []\n",
    "        for idx, text in enumerate(data):\n",
    "            input_ids, segment_ids = convert_example_recall_infer({idx: text[0]}, tokenizer)\n",
    "            title_ids, title_segment_ids = convert_example_recall_infer({\n",
    "                idx: text[1]\n",
    "            }, tokenizer)\n",
    "            examples.append(\n",
    "                (input_ids, segment_ids, title_ids, title_segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        query_ids, query_segment_ids, title_ids, title_segment_ids = batchify_fn(\n",
    "            examples)\n",
    "        self.input_handles[0].copy_from_cpu(query_ids)\n",
    "        self.input_handles[1].copy_from_cpu(query_segment_ids)\n",
    "        self.predictor.run()\n",
    "        query_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        self.input_handles[0].copy_from_cpu(title_ids)\n",
    "        self.input_handles[1].copy_from_cpu(title_segment_ids)\n",
    "        self.predictor.run()\n",
    "        title_logits = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        result = [\n",
    "            float(1 - spatial.distance.cosine(arr1, arr2))\n",
    "            for arr1, arr2 in zip(query_logits, title_logits)\n",
    "        ]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = 'output/recall'\n",
    "device='gpu'\n",
    "max_seq_length=64\n",
    "use_tensorrt = False\n",
    "batch_size =32 \n",
    "precision = 'fp32'\n",
    "cpu_threads = 1\n",
    "enable_mkldnn =False\n",
    "predictor = RecallPredictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "\n",
    "\n",
    "id2corpus = {0: '国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据'}\n",
    "corpus_list = [{idx: text} for idx, text in id2corpus.items()]\n",
    "res = predictor.extract_embedding(corpus_list, tokenizer)\n",
    "print('抽取向量')\n",
    "print(res.shape)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.267653Z",
     "iopub.status.idle": "2023-08-11T07:48:49.267946Z",
     "shell.execute_reply": "2023-08-11T07:48:49.267814Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.267801Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_list = [['中西方语言与文化的差异', '中西方文化差异以及语言体现中西方文化,差异,语言体现'],\n",
    "                   ['中西方语言与文化的差异', '飞桨致力于让深度学习技术的创新与应用更简单']]\n",
    "res = predictor.predict(corpus_list, tokenizer)\n",
    "print('计算相似度')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "输入的样本为：\n",
    "\n",
    "```\n",
    "国有企业引入非国有资本对创新绩效的影响——基于制造业国有上市公司的经验证据\n",
    "```\n",
    "\n",
    "下面分别是抽取的向量和召回的结果：\n",
    "\n",
    "```\n",
    "[1, 256]\n",
    "[[ 0.06374735 -0.08051944  0.05118101 -0.05855767 -0.06969483  0.05318566\n",
    "   0.079629    0.02667932 -0.04501902 -0.01187392  0.09590752 -0.05831281\n",
    "   ....\n",
    "5677638 国有股权参股对家族企业创新投入的影响混合所有制改革,国有股权,家族企业,创新投入 0.5417419672012329\n",
    "1321645 高管政治联系对民营企业创新绩效的影响——董事会治理行为的非线性中介效应高管政治联系,创新绩效,民营上市公司,董事会治理行为,中介效应 0.5445536375045776\n",
    "1340319 国有控股上市公司资产并购重组风险探讨国有控股上市公司,并购重组,防范对策 0.5515031218528748\n",
    "....\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.268770Z",
     "iopub.status.idle": "2023-08-11T07:48:49.269060Z",
     "shell.execute_reply": "2023-08-11T07:48:49.268926Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.268914Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 构建读取函数，读取原始数据\n",
    "def read(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        neg_title=row['neg_title']\n",
    "        yield {'query':query, 'title':title,'neg_title':neg_title}\n",
    "\n",
    "def read_test(src_path, is_predict=False):\n",
    "    data=pd.read_csv(src_path,sep='\\t')\n",
    "    for index, row in tqdm(data.iterrows()):\n",
    "        query=row['query']\n",
    "        title=row['title']\n",
    "        label=row['label']\n",
    "        yield {'query':query, 'title':title,'label':label}\n",
    "\n",
    "\n",
    "test_file='dev_ranking_demo.csv'\n",
    "train_file='train_ranking_demo.csv'\n",
    "\n",
    "train_ds=load_dataset(read,src_path=train_file,lazy=False)\n",
    "dev_ds=load_dataset(read_test,src_path=test_file,lazy=False)\n",
    "print('打印一条训练集')\n",
    "print(train_ds[0])\n",
    "print('打印一条验证集')\n",
    "print(dev_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:05:48.871998Z",
     "iopub.status.busy": "2024-08-06T08:05:48.870755Z",
     "iopub.status.idle": "2024-08-06T08:05:48.886389Z",
     "shell.execute_reply": "2024-08-06T08:05:48.885296Z",
     "shell.execute_reply.started": "2024-08-06T08:05:48.871931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PairwiseMatching(nn.Layer):\n",
    "    def __init__(self, pretrained_model, dropout=None, margin=0.1):\n",
    "        super().__init__()\n",
    "        self.ptm = pretrained_model\n",
    "        self.dropout = nn.Dropout(dropout if dropout is not None else 0.1)\n",
    "        self.margin = margin\n",
    "\n",
    "        # hidden_size -> 1, calculate similarity\n",
    "        self.similarity = nn.Linear(self.ptm.config[\"hidden_size\"], 1)\n",
    "\n",
    "    # 用于导出静态图模型来计算概率\n",
    "    @paddle.jit.to_static(input_spec=[paddle.static.InputSpec(shape=[None, None], dtype='int64'),paddle.static.InputSpec(shape=[None, None], dtype='int64')])\n",
    "    def get_pooled_embedding(self,\n",
    "                             input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             position_ids=None,\n",
    "                             attention_mask=None):\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids,\n",
    "                                        position_ids, attention_mask)\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        # 计算相似度\n",
    "        sim = self.similarity(cls_embedding)\n",
    "        return sim\n",
    "\n",
    "\n",
    "    def predict(self,\n",
    "                input_ids,\n",
    "                token_type_ids=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        _, cls_embedding = self.ptm(input_ids, token_type_ids, position_ids,\n",
    "                                    attention_mask)\n",
    "\n",
    "        cls_embedding = self.dropout(cls_embedding)\n",
    "        sim_score = self.similarity(cls_embedding)\n",
    "        sim_score = F.sigmoid(sim_score)\n",
    "        return sim_score\n",
    "\n",
    "    def forward(self,\n",
    "                pos_input_ids,\n",
    "                neg_input_ids,\n",
    "                pos_token_type_ids=None,\n",
    "                neg_token_type_ids=None,\n",
    "                pos_position_ids=None,\n",
    "                neg_position_ids=None,\n",
    "                pos_attention_mask=None,\n",
    "                neg_attention_mask=None):\n",
    "\n",
    "        _, pos_cls_embedding = self.ptm(pos_input_ids, pos_token_type_ids,\n",
    "                                        pos_position_ids, pos_attention_mask)\n",
    "\n",
    "        _, neg_cls_embedding = self.ptm(neg_input_ids, neg_token_type_ids,\n",
    "                                        neg_position_ids, neg_attention_mask)\n",
    "\n",
    "        pos_embedding = self.dropout(pos_cls_embedding)\n",
    "        neg_embedding = self.dropout(neg_cls_embedding)\n",
    "\n",
    "        pos_sim = self.similarity(pos_embedding)\n",
    "        neg_sim = self.similarity(neg_embedding)\n",
    "\n",
    "        pos_sim = F.sigmoid(pos_sim)\n",
    "        neg_sim = F.sigmoid(neg_sim)\n",
    "\n",
    "        labels = paddle.full(\n",
    "            shape=[pos_cls_embedding.shape[0]], fill_value=1.0, dtype='float32')\n",
    "\n",
    "        loss = F.margin_ranking_loss(\n",
    "            pos_sim, neg_sim, labels, margin=self.margin)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:05:53.515317Z",
     "iopub.status.busy": "2024-08-06T08:05:53.514656Z",
     "iopub.status.idle": "2024-08-06T08:05:53.520958Z",
     "shell.execute_reply": "2024-08-06T08:05:53.519962Z",
     "shell.execute_reply.started": "2024-08-06T08:05:53.515265Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 关键参数\n",
    "margin=0.2 # 推荐取值 0.0 ~ 0.2\n",
    "eval_step=100\n",
    "max_seq_length=128\n",
    "epochs=3\n",
    "batch_size=32\n",
    "warmup_proportion=0.0\n",
    "weight_decay=0.0\n",
    "save_step=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.272944Z",
     "iopub.status.idle": "2023-08-11T07:48:49.273237Z",
     "shell.execute_reply": "2023-08-11T07:48:49.273104Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.273091Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieModel.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(\n",
    "        'ernie-3.0-medium-zh')\n",
    "\n",
    "trans_func_train = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length)\n",
    "\n",
    "trans_func_eval = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"eval\")\n",
    "\n",
    "batchify_fn_train = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pos_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pos_pair_segment\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # neg_pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64')  # neg_pair_segment\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "batchify_fn_eval = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # pair_input\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # pair_segment\n",
    "        Stack(dtype=\"int64\")  # label\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "train_data_loader = create_dataloader(\n",
    "        train_ds,\n",
    "        mode='train',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_train,\n",
    "        trans_fn=trans_func_train)\n",
    "\n",
    "dev_data_loader = create_dataloader(\n",
    "        dev_ds,\n",
    "        mode='dev',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn_eval,\n",
    "        trans_fn=trans_func_eval)\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.274325Z",
     "iopub.status.idle": "2023-08-11T07:48:49.274630Z",
     "shell.execute_reply": "2023-08-11T07:48:49.274487Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.274474Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 打印训练集的batch数据\n",
    "for item in train_data_loader:\n",
    "    print(item)\n",
    "    break\n",
    "\n",
    "# 打印验证集的batch数据\n",
    "for item in dev_data_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:06:07.517063Z",
     "iopub.status.busy": "2024-08-06T08:06:07.515502Z",
     "iopub.status.idle": "2024-08-06T08:06:07.524706Z",
     "shell.execute_reply": "2024-08-06T08:06:07.523800Z",
     "shell.execute_reply.started": "2024-08-06T08:06:07.516994Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@paddle.no_grad()\n",
    "def evaluate(model, metric, data_loader, phase=\"dev\"):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        # 类别为正的概率\n",
    "        pos_probs = model.predict(input_ids=input_ids, token_type_ids=token_type_ids)\n",
    "        # 类别为负的概率\n",
    "        neg_probs = 1.0 - pos_probs\n",
    "\n",
    "        preds = np.concatenate((neg_probs, pos_probs), axis=1)\n",
    "        metric.update(preds=preds, labels=labels)\n",
    "\n",
    "    print(\"eval_{} auc:{:.3}\".format(phase, metric.accumulate()))\n",
    "    metric.reset()\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.276985Z",
     "iopub.status.idle": "2023-08-11T07:48:49.277284Z",
     "shell.execute_reply": "2023-08-11T07:48:49.277148Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.277135Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def do_train(model,train_data_loader,dev_data_loader):\n",
    "\n",
    "    num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "    lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "    # Generate parameter names needed to perform weight decay.\n",
    "    # All bias and LayerNorm parameters are excluded.\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "        learning_rate=lr_scheduler,\n",
    "        parameters=model.parameters(),\n",
    "        weight_decay=weight_decay,\n",
    "        apply_decay_param_fun=lambda x: x in decay_params)\n",
    "    # 使用AUC作为评估指标\n",
    "    metric = paddle.metric.Auc()\n",
    "\n",
    "    global_step = 0\n",
    "    tic_train = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            pos_input_ids, pos_token_type_ids, neg_input_ids, neg_token_type_ids = batch\n",
    "\n",
    "            loss = model(\n",
    "                pos_input_ids=pos_input_ids,\n",
    "                neg_input_ids=neg_input_ids,\n",
    "                pos_token_type_ids=pos_token_type_ids,\n",
    "                neg_token_type_ids=neg_token_type_ids)\n",
    "            # 每隔10个step打印日志\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0 :\n",
    "                print(\n",
    "                    \"global step %d, epoch: %d, batch: %d, loss: %.5f, speed: %.2f step/s\"\n",
    "                    % (global_step, epoch, step, loss,\n",
    "                       10 / (time.time() - tic_train)))\n",
    "                tic_train = time.time()\n",
    "            # 反向求梯度\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "            # 每隔eval_step进行评估\n",
    "            if global_step % eval_step == 0:\n",
    "                evaluate(model, metric, dev_data_loader, \"dev\")\n",
    "            # 每隔save_steps保存模型\n",
    "            if global_step % save_step == 0:\n",
    "                save_path = os.path.join(save_dir, \"model_%d\" % global_step)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                save_param_path = os.path.join(save_path, 'model_state.pdparams')\n",
    "                paddle.save(model.state_dict(), save_param_path)\n",
    "                tokenizer.save_pretrained(save_path)\n",
    "\n",
    "do_train(model,train_data_loader,dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.278084Z",
     "iopub.status.idle": "2023-08-11T07:48:49.278399Z",
     "shell.execute_reply": "2023-08-11T07:48:49.278264Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.278251Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(not os.path.exists('ernie_gram_sort.zip')):\n",
    "    get_path_from_url('https://bj.bcebos.com/v1/paddlenlp/models/ernie_gram_sort.zip',root_dir='.')\n",
    "!unzip -o ernie_gram_sort.zip -d pretrained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.279265Z",
     "iopub.status.idle": "2023-08-11T07:48:49.279565Z",
     "shell.execute_reply": "2023-08-11T07:48:49.279422Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.279409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = ppnlp.transformers.ErnieGramModel.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "tokenizer = ppnlp.transformers.ErnieGramTokenizer.from_pretrained(\n",
    "        'ernie-gram-zh')\n",
    "model = PairwiseMatching(pretrained_model, margin=margin)\n",
    "init_from_ckpt='pretrained/model_30000/model_state.pdparams'\n",
    "state_dict = paddle.load(init_from_ckpt)\n",
    "model.set_dict(state_dict)\n",
    "metric = paddle.metric.Auc()\n",
    "evaluate(model, metric, dev_data_loader, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型推理\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.280615Z",
     "iopub.status.idle": "2023-08-11T07:48:49.280919Z",
     "shell.execute_reply": "2023-08-11T07:48:49.280781Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.280768Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data import read_text_pair\n",
    "input_file='test_pairwise.csv'\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印一条数据\n",
    "print(valid_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.281797Z",
     "iopub.status.idle": "2023-08-11T07:48:49.282089Z",
     "shell.execute_reply": "2023-08-11T07:48:49.281956Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.281943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_func = partial(\n",
    "        convert_pairwise_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        phase=\"predict\")\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input_ids\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id, dtype='int64'),  # segment_ids\n",
    "    ): [data for data in fn(samples)]\n",
    "\n",
    "test_data_loader = create_dataloader(\n",
    "        valid_ds,\n",
    "        mode='predict',\n",
    "        batch_size=batch_size,\n",
    "        batchify_fn=batchify_fn,\n",
    "        trans_fn=trans_func)\n",
    "# 打印测试的样本\n",
    "for item in test_data_loader:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.283145Z",
     "iopub.status.idle": "2023-08-11T07:48:49.283435Z",
     "shell.execute_reply": "2023-08-11T07:48:49.283303Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.283291Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "\n",
    "    batch_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with paddle.no_grad():\n",
    "        for batch_data in data_loader:\n",
    "            input_ids, token_type_ids = batch_data\n",
    "\n",
    "            input_ids = paddle.to_tensor(input_ids, dtype='int64')\n",
    "            token_type_ids = paddle.to_tensor(token_type_ids, dtype='int64')\n",
    "            # 输入query title pair得到预测的概率\n",
    "            batch_prob = model.predict(\n",
    "                input_ids=input_ids, token_type_ids=token_type_ids).numpy()\n",
    "\n",
    "            batch_probs.append(batch_prob)\n",
    "        if(len(batch_prob)==1):\n",
    "            batch_probs=np.array(batch_probs)\n",
    "        else:\n",
    "            batch_probs = np.concatenate(batch_probs, axis=0)\n",
    "        return batch_probs\n",
    "\n",
    "\n",
    "\n",
    "y_probs = predict(model, test_data_loader)\n",
    "valid_ds = load_dataset(read_text_pair, data_path=input_file, lazy=False)\n",
    "# 打印输出\n",
    "for idx, prob in enumerate(y_probs):\n",
    "    text_pair = valid_ds[idx]\n",
    "    text_pair[\"pred_prob\"] = prob[0]\n",
    "    print(text_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.284491Z",
     "iopub.status.idle": "2023-08-11T07:48:49.284795Z",
     "shell.execute_reply": "2023-08-11T07:48:49.284659Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.284646Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path='output/rank'\n",
    "model.eval()\n",
    "\n",
    "# Convert to static graph with specific input description\n",
    "model = paddle.jit.to_static(\n",
    "        model,\n",
    "        input_spec=[\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\"),  # input_ids\n",
    "            paddle.static.InputSpec(\n",
    "                shape=[None, None], dtype=\"int64\")  # segment_ids\n",
    "        ])\n",
    "# Save in static graph model.\n",
    "save_path = os.path.join(output_path, \"inference\")\n",
    "paddle.jit.save(model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.286033Z",
     "iopub.status.idle": "2023-08-11T07:48:49.286365Z",
     "shell.execute_reply": "2023-08-11T07:48:49.286225Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.286211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(self,\n",
    "                 model_dir,\n",
    "                 device=\"gpu\",\n",
    "                 max_seq_length=128,\n",
    "                 batch_size=32,\n",
    "                 use_tensorrt=False,\n",
    "                 precision=\"fp32\",\n",
    "                 cpu_threads=10,\n",
    "                 enable_mkldnn=False):\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        model_file = model_dir + \"/inference.get_pooled_embedding.pdmodel\"\n",
    "        params_file = model_dir + \"/inference.get_pooled_embedding.pdiparams\"\n",
    "        if not os.path.exists(model_file):\n",
    "            raise ValueError(\"not find model file path {}\".format(model_file))\n",
    "        if not os.path.exists(params_file):\n",
    "            raise ValueError(\"not find params file path {}\".format(params_file))\n",
    "        config = paddle.inference.Config(model_file, params_file)\n",
    "\n",
    "        if device == \"gpu\":\n",
    "            # set GPU configs accordingly\n",
    "            # such as intialize the gpu memory, enable tensorrt\n",
    "            config.enable_use_gpu(100, 0)\n",
    "            precision_map = {\n",
    "                \"fp16\": inference.PrecisionType.Half,\n",
    "                \"fp32\": inference.PrecisionType.Float32,\n",
    "                \"int8\": inference.PrecisionType.Int8\n",
    "            }\n",
    "            precision_mode = precision_map[precision]\n",
    "\n",
    "            if use_tensorrt:\n",
    "                config.enable_tensorrt_engine(\n",
    "                    max_batch_size=batch_size,\n",
    "                    min_subgraph_size=30,\n",
    "                    precision_mode=precision_mode)\n",
    "        elif device == \"cpu\":\n",
    "            # set CPU configs accordingly,\n",
    "            # such as enable_mkldnn, set_cpu_math_library_num_threads\n",
    "            config.disable_gpu()\n",
    "            if enable_mkldnn:\n",
    "                # cache 10 different shapes for mkldnn to avoid memory leak\n",
    "                config.set_mkldnn_cache_capacity(10)\n",
    "                config.enable_mkldnn()\n",
    "            config.set_cpu_math_library_num_threads(cpu_threads)\n",
    "        elif device == \"xpu\":\n",
    "            # set XPU configs accordingly\n",
    "            config.enable_xpu(100)\n",
    "\n",
    "        config.switch_use_feed_fetch_ops(False)\n",
    "        self.predictor = paddle.inference.create_predictor(config)\n",
    "        self.input_handles = [\n",
    "            self.predictor.get_input_handle(name)\n",
    "            for name in self.predictor.get_input_names()\n",
    "        ]\n",
    "        self.output_handle = self.predictor.get_output_handle(\n",
    "            self.predictor.get_output_names()[0])\n",
    "\n",
    "     \n",
    "\n",
    "    def predict(self, data, tokenizer):\n",
    "        \n",
    "        examples = []\n",
    "        for text in data:\n",
    "            input_ids, segment_ids = convert_example_ranking(\n",
    "                text,\n",
    "                tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                is_test=True)\n",
    "            examples.append((input_ids, segment_ids))\n",
    "\n",
    "        batchify_fn = lambda samples, fn=Tuple(\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # input\n",
    "            Pad(axis=0, pad_val=tokenizer.pad_token_id, dtype='int64'),  # segment\n",
    "        ): fn(samples)\n",
    "\n",
    "\n",
    "        input_ids, segment_ids = batchify_fn(examples)\n",
    "        self.input_handles[0].copy_from_cpu(input_ids)\n",
    "        self.input_handles[1].copy_from_cpu(segment_ids)\n",
    "        self.predictor.run()\n",
    "        sim_score = self.output_handle.copy_to_cpu()\n",
    "\n",
    "        sim_score = expit(sim_score)\n",
    "\n",
    "        return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.287225Z",
     "iopub.status.idle": "2023-08-11T07:48:49.287529Z",
     "shell.execute_reply": "2023-08-11T07:48:49.287386Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.287374Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_example_ranking(example, tokenizer, max_seq_length=512, is_test=False):\n",
    "\n",
    "    query, title = example[\"query\"], example[\"title\"]\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        text=query, text_pair=title, max_seq_len=max_seq_length)\n",
    "\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "input_file='test_pairwise.csv'\n",
    "\n",
    "test_ds = load_dataset(read_text_pair,data_path=input_file, lazy=False)\n",
    "\n",
    "data = [{'query': d['query'], 'title': d['title']} for d in test_ds]\n",
    "\n",
    "batches = [\n",
    "        data[idx:idx + batch_size]\n",
    "        for idx in range(0, len(data), batch_size)\n",
    "    ]\n",
    "print(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T07:48:49.288415Z",
     "iopub.status.idle": "2023-08-11T07:48:49.288721Z",
     "shell.execute_reply": "2023-08-11T07:48:49.288587Z",
     "shell.execute_reply.started": "2023-08-11T07:48:49.288574Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dir='output/rank'\n",
    "device='gpu'\n",
    "max_seq_length=128\n",
    "batch_size=32\n",
    "# 可以安装对应的Tensorrt之后进行加速\n",
    "use_tensorrt=False\n",
    "# 精度，也可以选择fp16，精度几乎无损\n",
    "precision='fp32'\n",
    "# cpu的线程数目\n",
    "cpu_threads=10\n",
    "# 可以在CPU的情况下进行加速\n",
    "enable_mkldnn=False\n",
    "\n",
    "predictor = Predictor(model_dir, device, max_seq_length,\n",
    "                          batch_size, use_tensorrt, precision,\n",
    "                          cpu_threads, enable_mkldnn)\n",
    "results = []\n",
    "for batch_data in batches:\n",
    "    results.extend(predictor.predict(batch_data, tokenizer))\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t prob: {}'.format(text, results[idx]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
