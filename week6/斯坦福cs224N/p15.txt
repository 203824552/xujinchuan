为模型添加知识：有三种较为常见的方法。
大语言模型学习的文本够多是否可以作为知识库？还在推进过程当中。优势在于，不需要进行手动注释，且可以通过一些推理进行没有的答案的生成（但可能会因此产生幻觉现象，从而难以信任）。
方法一，添加预训练的嵌入，增加实体嵌入，实体链接的目的则是找出拥有歧义的句子，到底选择的是哪一个实体。所以添加预训练实体嵌入的难点在于如何与现有的词嵌入空间合并，一种具体的实施则是，给嵌入曾增加一些新的空间，直接进行融合。
方法二，使用外部存储器或键值来让模型访问知识图谱三元组或上下文信息，这样的话方法更为直接。一种方法是在知识图谱上调节语言模型，通过找到实体和得分最高的关系，从而可以在本地图谱找到所需要的词汇（三元实体组合较为常见）。若不存在本地，则需要从完整的知识图谱中进行寻找。键值是上下文的表示，可以根据键值找到高概率的输出。
方法三，修改训练数据以为模型添加知识，训练时希望模型可以预测提及是真是假。是否特别有效则有待考证。
但是三种方法可以混合使用以达到更好的效果。
对于大语言模型的测试体系较为充足，多种测试轮番使用从而得到模型的性能。事实上，可能prompt的影响也非常的明显。
