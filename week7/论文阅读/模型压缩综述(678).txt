LC算法与其他算法

基于LC算法可以有多种压缩形式，进行对应的调整即可，算是一个基础的框架思路。
LC算法与直接压缩算法复杂度差距并不大因为C的训练时间数量级较小。而由于直接压缩带来的损失，可以通过重新训练对于直接压缩模型进行修正，但在高度压缩的情况下，其效果并不如LC算法。
并且LC算法还涉及到了一些其他算法，比如坐标辅助算法，他们甚至在参数嵌入的帮助下，可以视为同样一种方法。

泛化性往往也是一个模型重要的指标，那么对于模型压缩，泛化性也是该进行考虑的一部分因素，而对于LC算法，则是通过机器自身进行给定大小的最优子集的搜索，从而，可以确定实现足以满足当前应用要求的目标损失的最⼩模型。总之，神经网络中模型选择的⼀个好策略是训练⼀个足够⼤的参考模型并尽可能地压缩它。

LC算法更像是一种将训练和压缩进行组合并建立沟通的方法，从而更有效的进行模型压缩。