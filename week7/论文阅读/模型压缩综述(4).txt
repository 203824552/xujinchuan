LC算法（学习，压缩）
尽管该约束问题（模型压缩） 可以通过多种⾮凸优化算法来解决，但关键在于利用参数可分离性，我们可以通过惩罚⽅法和交替优化来实现这⼀点。常用的惩罚方法有quadratic
penalty (QP) and the augmented Lagrangian (AL)。
该方法分为两部分，第一部分是学习，争取找到最小的损失值和参数调整情况（正则化），第二部分是压缩，尽量使得压缩和解压缩差距较小。
LC算法是一个普遍的提出，学习过程只需要添加部分损失值，而压缩过程，就可以根据自己的压缩方法进行定义，改动不多。
运行过程往往当压缩差距满足我们所设计的精度即可结束。
在问题
直接压缩模型意义上不是最优的，因为压缩忽略了学习任务；权重的最佳压缩不⼀定是该任务的最佳压缩模型。
