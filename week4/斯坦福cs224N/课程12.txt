自然语言生成：翻译，数据分析，摘要都是该任务的一种，ChatGPT是一个较好的NLG系统。
在进行语言生成的时候，一般采用自回归的模式。
模型在反复重复后会对输出的语言得到更大的概率，即使在参数极大的模型中也会出现这种问题，因此为了解决这个问题，可以手动解决，不允许连续出现三次相同的回复（最简单粗暴的办法），或者对重复内容设置惩罚机制，（可以通过损失值调整等实现）。
为了更好的模拟人类生成语言的模式，一种方法可以是，我们将不需要的词汇概率归零，只选择topk的样本，k的值可以根据任务的开放程度进行选择。如果我们根据概率分数，进行k的自适应选择，可以更好的提高各种情况的精确度。可以使用温度超参数，通过除以温度参数以改变分布的大小概率，温度越低得到的输出就越少，反之亦然。
适当设计奖励机制，激励模型，当有些时候高分数并不完全等价于好的效果。

大模型训练三步，预训练，微调，根据人类反馈强化学习！

评价指标有很多，有内容重叠指标，即和人类提供的文本进行相似度的计算（相同词汇），但显然会有很多的问题存在。因此还需要检查语义相似性（根据词嵌入，进行向量之间的相似性）。对于开放式创造，我们没有参考文本，则需要新的评估方法，核心在于建立有意义的距离度量，否则难以表达（因为长文本等空间过于复杂）。

自然语言生成还应该确定道德标准，如限制部分铭感词汇等等。