机器翻译：很早就开始的项目，不过50-60年代效果不佳。1990-2010，此时我们需要大量的对比数据，如句子和翻译的句子对，才能进行学习，和概率分配，数据结构一般则是一个矩阵存储，保存下来概率较大的对应翻译部分，称之为统计机器翻译。
使用神经网络进行机器翻译：seq2seq，一般涉及两个神经网络，input将句子进行编码，最后进行input即encoder RNN；然后再独立的使用decoder RNN进行句子的翻译并输出。整体训练过程如下：先找到大量的平行句子的数据集，从而可以进行编码，然后在目标语言生成器中传递预测，但反向传播可以一起更新编码器。多层堆叠的RNN会更强大，纵使总数据量（模型参数）一样。翻译时，可以通过k个可能，以便最终可以选择概率更大的翻译生成，否则只选择一个容易在中途失去得到最佳答案的机会，由于长句子可能得到的概率较低，因此采用平均化使得概率大小更加公平。
评估机器翻译：可以通过人类打分但成本较高，因此提出了BLUE方法，将机器翻译与目标翻译用N-gram方法对比计算，自动化的方法才是正确合理高效的使用。
Attention：直接连接encoder和decoder，根据点积来判断哪个单词和当前解码器的状态最为相似，以进行选择。（相当于每次都和原句子中的单词进行了比较从而获得更多信息）