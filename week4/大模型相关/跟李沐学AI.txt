GPU有大量小的计算核心，因此适合简单的重复简单运算，CPU则适合复杂的逻辑运算。模型前向传播的中间结果需要在显存中保存。
数据并行则是，将数据切分，反向传播时再将梯度取平均值或者求和等规约方法，最后所有显卡都得到我们需要的数据（可以是全部梯度也可以是部分梯度），从而进行反向传播。可以不需要参数服务器，只需要注意保持多个显卡数据保持一致即可。
模型并行则是，可以把线形层分开，然后最后将线形层得到的结果进行拼接即可，即mxn，nxs=mxs；因此只需要原本模型1/n的参数即可。
并行时每张显卡亦可以只保存部分参数，需要的时候再选择组合全部的参数。
也可以对于模型的层分别放在不同的显卡上，减少了每个显卡的存储，但是利用率却有所下降。
混合精度训练，FP32是一般的选择，低精度不过可能会面临参数损失的问题，所以采用了混合精度以减小参数大小。异步的操作，可以进行一定的并行。也可以通过适当的重复计算，减少模型的存储量。
知识蒸馏，把多个模型中有用的知识提取出来，通过两个模型训练出更小更有效的模型。
模型剪枝：通过测试找到不太重要的参数。模型量化：把浮点数适当以int方式或其他数据类型进行保存。参数共享：多层模型使用相同的参数，训练结果还行的话是可以接受的。openBMP，bminf可以使用一些大模型推理。

大模型：
信息检索，给出问题并进行相关的回答，一般根据相关性排序。亦有各种相关指标，进行对应分数的计算，一般与返回的相关文章数量相关。而使用大模型时，则可以通过映射到向量空间，进行更合理的语义匹配，比传统的词汇相似度更精确。
机器问答，传统的则是基于知识库。在以前也有很多小模型进行问题编码。而在大模型中，只需要基于prompt进行询问即可，进行了流程的简化。开放式回答则是根据学习的知识进行回答，而不是简单的对于文章的概括，大模型存储的知识量是很大的。
文本生成，可以有data-text或者text-text，编码后不断选择概率最大的选择进行语言的生成，之前所描述的微调方法同样适用于文本生成任务。

大模型的交叉应用：
生物医学，可以对各种可以表示成序列的数据进行处理，有对专门的实体进行学习，在文本中发掘一些关系，帮助从业者进行知识抽取。亦可以用在辅助诊疗任务中，更大的提供医疗资源，其中的对话系统，应该也有足够的思维能力，比如通过知识图谱进行分析。NLP可以对很多物质进行表示，比如DNA，蛋白质之类。可以进行文本和对应的化学结构进行交互，模型可以达到一定的水平。






