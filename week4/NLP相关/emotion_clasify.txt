本次实验主要目的还是熟悉pytorch中一些模型的构建和使用。
采用的是豆瓣影评数据集，通过token化和index化完成数据集的构造，然后就是训练环节
本次共采用了三种模型的构造进行尝试：
一，Word Averaging，把每个单词都通过Embedding层投射成word embedding vector,然后后把一句话中的所有word vector做个平均，就是整个句子的vector表示了。接下来把这个sentence vector传入一个Linear层，做分类即可。
二，一个双向的两层LSTM模型，不同层h1，h2分别从相反的方向进行信息的传递。
三，采用一个CNN模型。NLP中多数任务的输入都不再是图片像素，而是以矩阵表示的句子或者文档。矩阵的每一行对应一个token，一般是一个单词或者字符。也即每行代表一个词向量，通常是像 word2vec 或 GloVe 词嵌入(word embedding，低维表示)，但这些只能是独热码向量(one-hot vector)，10个单词的句子用100维嵌入，那输入矩阵就是10x100，这就是我们的“图像”。基于此可以进行学习，且由于情感分类等分类任务并不是十分注重局部信息，所以最终也在此次取得了更好的效果。