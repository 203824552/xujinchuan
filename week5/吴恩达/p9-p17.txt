大语言模型微调：
训练一个LLM会消耗大量的资源，微调才是一般情况下我们所使用的方式。（gpt3到chatgpt就是一种微调）
微调模型可以在对应邻域得到更准确的和细致的判断。
微调对比提示词，提示词前期成本较低，提示词不能输出大量自己的数据，并且难以纠正错误。微调则相反，可以使用任意数量的数据，包括很多新信息，对于后期频繁使用效果较好，不过就是微调数据集需要有较高的质量，二者精通范围不同。
huggingface提供部分可以直接调用预训练模型的功能。
指令微调，教给模型一些新的类型，高质量的数据非常重要，多样性和逻辑完整很重要。
数据集首先要收集数据对，然后合并加入提示词模板，然后token化最后再划分。token.decoder就可以还原，填充和截断是一种常用以统一的方法。
训练方式，还是类似于神经网络，根据损失值反向传播。
评估模型，对于大模型通常包含多种测试，因为涉及较多种类。

微调首先需要明确自己的任务，数据集甚至可以用大模型来辅助创建（通过prompt），不同任务复杂度，对应不同的模型大小，选择适合自己的大小。LoRa有效选择修改参数的范围，