对于依赖关系，一些特征分布较为稀疏，一些会不太完整，甚至会非常昂贵，这些都导致了学习的困难。因此可以选择使用神经分类器，而不是符号依赖解析器

将每个单词表示为一个词嵌入。
softmax是一种较为简单的分类器，且是一种线性分类器，很多分类模型顶层都是一个softmax，但是因为其中的隐藏层不同，从而可以进行非线性的分类。

基于图的依赖关系解析器效果可能更好，例如对于上下文进行评分从而生成图结构。正则化的作用有让部分无效参数，减小以减小影响。往往dropout效果更好（将部分元素归零）。

大型神经网络会在训练数据上过度拟合，但是他们有足够的能力对于新的例子进行推理（包罗万象）

神经网络必须要有非线性，否则归结为单一的线性处理，表达能力是有限的。ReLu是一种简单但是非常实用的非线性方法，（速度快亦是其优势）
注意控制学习率，才能有效的进行学习。

语言模型通常是对于下一个tokken的预测，或者是对于几个token（N-gram）就是一个用数据构建的概率模型，选取n个和n-1个单词的概率进行计算，巨大的概率表也是一个很大的问题，非常的消耗资源。现在则是用神经网络进行自己学习推理，如固定窗口分类器。RNN要包含前面的数值，就可以收到前文的影响，词向量也在不断的输入


